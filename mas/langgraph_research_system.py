"""
–°–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –æ—Ç—á—ë—Ç–æ–≤ –Ω–∞ LangGraph
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å —Å—É–ø–µ—Ä–≤–∏–∑–æ—Ä–æ–º –∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏
"""

import os
import json
import functools
from typing import Annotated, TypedDict, Literal

try:
    from langchain_core.messages import HumanMessage, BaseMessage
    from langchain_openai import ChatOpenAI
    from langchain_core.tools import tool
    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
    from langgraph.graph import StateGraph, START, END
    from langgraph.graph.message import add_messages
    from langgraph.checkpoint.sqlite import SqliteSaver
    from dotenv import load_dotenv
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–∫–µ—Ç—ã:")
    print("pip install langchain langchain-openai langgraph tavily-python python-dotenv")
    exit(1)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö API –∫–ª—é—á–µ–π
def check_api_keys():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö API –∫–ª—é—á–µ–π"""
    required_keys = {
        "OPENAI_API_KEY": "OpenAI API –∫–ª—é—á –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å GPT –º–æ–¥–µ–ª—è–º–∏",
        "TAVILY_API_KEY": "Tavily API –∫–ª—é—á –¥–ª—è –≤–µ–±-–ø–æ–∏—Å–∫–∞"
    }
    
    missing_keys = []
    for key, description in required_keys.items():
        if not os.getenv(key):
            missing_keys.append(f"  - {key}: {description}")
    
    if missing_keys:
        print("‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ API –∫–ª—é—á–∏:")
        print("\n".join(missing_keys))
        print("\n–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏:")
        print("OPENAI_API_KEY=your-openai-api-key-here")
        print("TAVILY_API_KEY=your-tavily-api-key-here")
        return False
    
    return True

# –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á–∏ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
if not check_api_keys():
    print("\nüí° –ü–æ–ª—É—á–∏—Ç–µ API –∫–ª—é—á–∏:")
    print("- OpenAI: https://platform.openai.com/api-keys")
    print("- Tavily: https://app.tavily.com/")
    exit(1)

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã
class ResearchState(TypedDict):
    """–°–æ—Å—Ç–æ—è–Ω–∏–µ –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω–æ–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã"""
    messages: Annotated[list[BaseMessage], add_messages]
    topic: str
    research_data: str
    analysis: str
    report: str
    next_agent: str

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
model = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)

# –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤
@tool
def web_search(query: str) -> str:
    """–ü–æ–∏—Å–∫ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ"""
    try:
        from tavily import TavilyClient
        client = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])
        results = client.search(query, max_results=5)
        
        formatted_results = []
        for result in results.get("results", []):
            formatted_results.append({
                "title": result.get("title", ""),
                "content": result.get("content", "")[:300] + "...",
                "url": result.get("url", "")
            })
        
        return json.dumps(formatted_results, ensure_ascii=False, indent=2)
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {str(e)}"

# –°–æ–∑–¥–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤
def create_agent_node(agent_name: str, system_prompt: str, tools: list = None):
    """–§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–∑–ª–æ–≤-–∞–≥–µ–Ω—Ç–æ–≤"""
    if tools is None:
        tools = []
    
    def agent_function(state: ResearchState) -> dict:
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{input}")
        ])
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–≥–µ–Ω—Ç–∞
        if agent_name == "researcher":
            input_text = f"–¢–µ–º–∞ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: {state['topic']}"
        elif agent_name == "analyst":
            input_text = f"–î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {state.get('research_data', '')}"
        elif agent_name == "writer":
            analysis_data = state.get('analysis', '')
            research_data = state.get('research_data', '')
            input_text = f"–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ: {research_data}\n\n–ê–Ω–∞–ª–∏–∑: {analysis_data}"
        else:
            input_text = state.get("topic", "")

        if tools:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏
            llm_with_tools = model.bind_tools(tools)
            response = llm_with_tools.invoke(prompt.format_messages(input=input_text))
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –≤—ã–∑–æ–≤—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤, –≤—ã–ø–æ–ª–Ω—è–µ–º –∏—Ö
            if response.tool_calls:
                tool_results = []
                for tool_call in response.tool_calls:
                    if tool_call["name"] == "web_search":
                        result = web_search.invoke(tool_call["args"])
                        tool_results.append(result)
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                combined_result = "\n".join(tool_results)
                final_response = f"{response.content}\n\n–î–∞–Ω–Ω—ã–µ –ø–æ–∏—Å–∫–∞:\n{combined_result}"
            else:
                final_response = response.content
        else:
            response = model.invoke(prompt.format_messages(input=input_text))
            final_response = response.content
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –ø–æ–ª–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        update_dict = {"messages": [HumanMessage(content=final_response, name=agent_name)]}
        
        if agent_name == "researcher":
            update_dict["research_data"] = final_response
        elif agent_name == "analyst":
            update_dict["analysis"] = final_response
        elif agent_name == "writer":
            update_dict["report"] = final_response
            
        return update_dict
    
    return agent_function

# –°–æ–∑–¥–∞–Ω–∏–µ —É–∑–ª–æ–≤ –∞–≥–µ–Ω—Ç–æ–≤
research_node = create_agent_node(
    "researcher",
    """–í—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ ‚Äî –Ω–∞–π—Ç–∏ –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ.
    –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ web_search –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞ –∏–∑ 10 –∫–ª—é—á–µ–≤—ã—Ö —Ñ–∞–∫—Ç–æ–≤.
    –¢–µ–∫—É—â–∏–π –≥–æ–¥: 2025. –§–æ–∫—É—Å–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö.""",
    tools=[web_search]
)

analysis_node = create_agent_node(
    "analyst",
    """–í—ã ‚Äî –∞–Ω–∞–ª–∏—Ç–∏–∫ –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –≤—ã–¥–µ–ª–∏—Ç–µ:
    1. –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ –∏ —Ç—Ä–µ–Ω–¥—ã
    2. –ö–ª—é—á–µ–≤—ã–µ —Ü–∏—Ñ—Ä—ã –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    3. –í–∞–∂–Ω—ã–µ –≤—ã–≤–æ–¥—ã –∏ –∏–Ω—Å–∞–π—Ç—ã
    4. –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∞–∑–≤–∏—Ç–∏—è"""
)

writer_node = create_agent_node(
    "writer",
    """–í—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–≤—Ç–æ—Ä —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –æ—Ç—á—ë—Ç–æ–≤. –ù–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–∑–¥–∞–π—Ç–µ 
    —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á—ë—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ —Ä–∞–∑–¥–µ–ª–∞–º–∏:
    
    # –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–µ–∑—é–º–µ
    # –ö–ª—é—á–µ–≤—ã–µ –Ω–∞—Ö–æ–¥–∫–∏
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    # –í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    
    –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏, —Å–ø–∏—Å–∫–∏ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏."""
)

# –°—É–ø–µ—Ä–≤–∏–∑–æ—Ä –¥–ª—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏
def supervisor_node(state: ResearchState) -> dict:
    """–°—É–ø–µ—Ä–≤–∏–∑–æ—Ä –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ"""
    if not state.get("research_data"):
        return {"next_agent": "researcher"}
    elif not state.get("analysis"):
        return {"next_agent": "analyst"}
    elif not state.get("report"):
        return {"next_agent": "writer"}
    else:
        return {"next_agent": "FINISH"}

def route_to_next_agent(state: ResearchState) -> Literal["researcher", "analyst", "writer", "end"]:
    """–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –∞–≥–µ–Ω—Ç—É"""
    next_agent = state.get("next_agent", "researcher")
    if next_agent == "FINISH":
        return "end"
    return next_agent

# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞
def create_research_graph():
    """–°–æ–∑–¥–∞–Ω–∏–µ –∏ –∫–æ–º–ø–∏–ª—è—Ü–∏—è –≥—Ä–∞—Ñ–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã"""
    workflow = StateGraph(ResearchState)
    
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —É–∑–ª–æ–≤
    workflow.add_node("supervisor", supervisor_node)
    workflow.add_node("researcher", research_node)
    workflow.add_node("analyst", analysis_node)
    workflow.add_node("writer", writer_node)
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä—ë–±–µ—Ä
    workflow.add_edge(START, "supervisor")
    
    # –£—Å–ª–æ–≤–Ω—ã–µ —Ä—ë–±—Ä–∞ –æ—Ç —Å—É–ø–µ—Ä–≤–∏–∑–æ—Ä–∞
    workflow.add_conditional_edges(
        "supervisor",
        route_to_next_agent,
        {
            "researcher": "researcher",
            "analyst": "analyst", 
            "writer": "writer",
            "end": END
        }
    )
    
    # –í–æ–∑–≤—Ä–∞—Ç –∫ —Å—É–ø–µ—Ä–≤–∏–∑–æ—Ä—É –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
    workflow.add_edge("researcher", "supervisor")
    workflow.add_edge("analyst", "supervisor")
    workflow.add_edge("writer", "supervisor")
    
    # –ö–æ–º–ø–∏–ª—è—Ü–∏—è —Å –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å—é (–∏—Å–ø–æ–ª—å–∑—É–µ–º InMemorySaver –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã)
    from langgraph.checkpoint.memory import InMemorySaver
    memory = InMemorySaver()
    return workflow.compile(checkpointer=memory)

# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∏—Å—Ç–µ–º—ã
def run_research_system(topic: str, verbose: bool = True):
    """
    –ó–∞–ø—É—Å–∫ –º–Ω–æ–≥–æ–∞–≥–µ–Ω—Ç–Ω–æ–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã
    
    Args:
        topic: –¢–µ–º–∞ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
        verbose: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —à–∞–≥–∏
    
    Returns:
        str: –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á—ë—Ç
    """
    app = create_research_graph()
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º thread_id
    config = {"configurable": {"thread_id": f"research_{hash(topic) % 10000}"}}
    
    # –ù–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    initial_state = {
        "messages": [HumanMessage(content=f"–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å —Ç–µ–º—É: {topic}")],
        "topic": topic,
        "next_agent": "researcher"
    }
    
    if verbose:
        print(f"üîç –ù–∞—á–∏–Ω–∞—é –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ç–µ–º—ã: {topic}\n")
    
    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å –ø–æ—Ç–æ–∫–æ–≤—ã–º –≤—ã–≤–æ–¥–æ–º
    final_state = None
    for step, state in enumerate(app.stream(initial_state, config), 1):
        if "__end__" not in state:
            current_step = list(state.keys())[0]
            if verbose:
                print(f"–®–∞–≥ {step}: –ê–≥–µ–Ω—Ç '{current_step}' –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–¥–∞—á—É...")
            final_state = state
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —á–µ—Ä–µ–∑ get_state
    try:
        state_snapshot = app.get_state(config)
        final_result = state_snapshot.values
    except Exception as e:
        if verbose:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ —á–µ—Ä–µ–∑ get_state: {e}")
        # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π invoke
        final_result = app.invoke(initial_state, config)
    
    return final_result.get("report", "–û—Ç—á—ë—Ç –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∑–∞–ø—É—Å–∫–∞ —Å–∏—Å—Ç–µ–º—ã
    try:
        topic = "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –≤ –º–µ–¥–∏—Ü–∏–Ω–µ: –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 2025"
        report = run_research_system(topic, verbose=True)
        
        print("\n" + "="*80)
        print("–ò–¢–û–ì–û–í–´–ô –û–¢–ß–Å–¢")
        print("="*80)
        print(report)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á—ë—Ç–∞
        with open("research_report_langgraph.md", "w", encoding="utf-8") as f:
            f.write(report)
        print(f"\n‚úÖ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ 'research_report_langgraph.md'")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫—É API –∫–ª—é—á–µ–π –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
def test_individual_agents():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤...")
    
    # –¢–µ—Å—Ç –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
    search_result = web_search.invoke({"query": "–ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –ò–ò 2025"})
    print(f"–ü–æ–∏—Å–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç: {len(search_result) > 100}")
    
    # –¢–µ—Å—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è
    test_state = ResearchState(
        messages=[],
        topic="—Ç–µ—Å—Ç",
        research_data="",
        analysis="",
        report="",
        next_agent="researcher"
    )
    
    supervisor_result = supervisor_node(test_state)
    print(f"–°—É–ø–µ—Ä–≤–∏–∑–æ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç: {supervisor_result.get('next_agent') == 'researcher'}")
    
    print("‚úÖ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã")

def visualize_graph():
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞—Ñ–∞"""
    print("üìä –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–∞...")
    
    try:
        app = create_research_graph()
        graph = app.get_graph()
        
        # ASCII
        print("\nüî§ ASCII —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:")
        try:
            graph.print_ascii()
        except:
            print("ASCII –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ")
        
        # Mermaid
        print("\nüåä Mermaid –∫–æ–¥:")
        try:
            mermaid = graph.draw_mermaid()
            print(mermaid)
            with open("research_graph.mmd", "w") as f:
                f.write(mermaid)
            print("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ research_graph.mmd")
        except Exception as e:
            print(f"Mermaid –æ—à–∏–±–∫–∞: {e}")
        
        # PNG
        print("\nüñºÔ∏è PNG –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:")
        try:
            png_data = graph.draw_mermaid_png()
            with open("research_graph.png", "wb") as f:
                f.write(png_data)
            print("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ research_graph.png")
        except Exception as e:
            print(f"PNG –æ—à–∏–±–∫–∞: {e}")
            print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: npm install -g @mermaid-js/mermaid-cli")
            
    except Exception as e:
        print(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞: {e}")

def create_interactive_graph():
    """–°–æ–∑–¥–∞—Ç—å –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é HTML –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é"""
    try:
        from pyvis.network import Network
        
        net = Network(height="600px", width="100%", directed=True)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —É–∑–ª—ã
        net.add_node("START", label="üöÄ START", color="#e1f5fe")
        net.add_node("supervisor", label="üéØ Supervisor", color="#fff3e0")
        net.add_node("researcher", label="üîç Researcher", color="#f3e5f5")
        net.add_node("analyst", label="üìä Analyst", color="#e8f5e8")
        net.add_node("writer", label="‚úçÔ∏è Writer", color="#fff8e1")
        net.add_node("END", label="üèÅ END", color="#ffebee")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤—è–∑–∏
        edges = [
            ("START", "supervisor"),
            ("supervisor", "researcher"),
            ("supervisor", "analyst"),
            ("supervisor", "writer"),
            ("supervisor", "END"),
            ("researcher", "supervisor"),
            ("analyst", "supervisor"),
            ("writer", "supervisor")
        ]
        
        for src, dst in edges:
            net.add_edge(src, dst)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        net.save_graph("research_graph_interactive.html")
        print("‚úÖ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≥—Ä–∞—Ñ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ research_graph_interactive.html")
        
    except ImportError:
        print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ PyVis: pip install pyvis")

def show_graph_ascii():
    """–ü–æ–∫–∞–∑–∞—Ç—å ASCII —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≥—Ä–∞—Ñ–∞"""
    app = create_research_graph()
    print("üî§ ASCII —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –≥—Ä–∞—Ñ–∞:")
    print("=" * 40)
    app.get_graph().print_ascii()

# –í—ã–∑–æ–≤–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é:
show_graph_ascii()

def show_graph_mermaid():
    """–ü–æ–∫–∞–∑–∞—Ç—å Mermaid –∫–æ–¥ –≥—Ä–∞—Ñ–∞"""
    app = create_research_graph()
    print("üåä Mermaid –∫–æ–¥:")
    print("=" * 40)
    mermaid_code = app.get_graph().draw_mermaid()
    print(mermaid_code)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    with open("research_graph.mmd", "w", encoding="utf-8") as f:
        f.write(mermaid_code)
    print("\n‚úÖ –ö–æ–¥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ research_graph.mmd")
    print("üí° –í—Å—Ç–∞–≤—å—Ç–µ –∫–æ–¥ –≤ https://mermaid.live –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞")

# –í—ã–∑–æ–≤–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é:
show_graph_mermaid()

def save_graph_png():
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞—Ñ –∫–∞–∫ PNG"""
    try:
        app = create_research_graph()
        graph_png = app.get_graph().draw_mermaid_png()
        with open("research_graph.png", "wb") as f:
            f.write(graph_png)
        print("‚úÖ PNG –≥—Ä–∞—Ñ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ research_graph.png")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ PNG: {e}")
        print("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ mermaid-cli: npm install -g @mermaid-js/mermaid-cli")