"""
examples.py - –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Web Research Agent

–≠—Ç–æ—Ç —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–∞
–¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π.
"""

import asyncio
import json
from typing import List
from web_research_agent import WebResearchAssistant, ResearchOutput
import os
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# ============================================================================
# –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
# ============================================================================

def example_basic_search():
    """–ü—Ä–∏–º–µ—Ä –±–∞–∑–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
    print("=" * 60)
    print("–ü–†–ò–ú–ï–† 1: –ë–∞–∑–æ–≤—ã–π –ø–æ–∏—Å–∫")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    assistant = WebResearchAssistant(
        openai_api_key=os.getenv("OPENAI_API_KEY"),
        tavily_api_key=os.getenv("TAVILY_API_KEY")
    )
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
    result = assistant.process_message_sync(
        "What are the main benefits of meditation for mental health?"
    )
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüìù –†–µ–∑—é–º–µ: {result.summary}")
    print(f"\nüéØ –û—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞: {result.categories.main_topic}")
    print(f"üìä –£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {result.confidence_level}")
    print(f"üí≠ –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {result.sentiment}")
    
    print("\nüîç –ö–ª—é—á–µ–≤—ã–µ –Ω–∞—Ö–æ–¥–∫–∏:")
    for i, finding in enumerate(result.key_findings[:3], 1):
        print(f"\n{i}. {finding.title}")
        print(f"   –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {'‚≠ê' * finding.relevance_score}")
        print(f"   {finding.description[:150]}...")
        print(f"   –ò—Å—Ç–æ—á–Ω–∏–∫: {finding.source}")
    
    return result


def example_conversation_with_memory():
    """–ü—Ä–∏–º–µ—Ä –¥–∏–∞–ª–æ–≥–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 2: –î–∏–∞–ª–æ–≥ —Å –ø–∞–º—è—Ç—å—é")
    print("=" * 60)
    
    assistant = WebResearchAssistant(
        openai_api_key=os.getenv("OPENAI_API_KEY"),
        tavily_api_key=os.getenv("TAVILY_API_KEY")
    )
    
    # –ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å
    print("\nüë§ –ó–∞–ø—Ä–æ—Å 1: –ß—Ç–æ —Ç–∞–∫–æ–µ –∫–≤–∞–Ω—Ç–æ–≤—ã–µ –∫–æ–º–ø—å—é—Ç–µ—Ä—ã?")
    result1 = assistant.process_message_sync(
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –∫–≤–∞–Ω—Ç–æ–≤—ã–µ –∫–æ–º–ø—å—é—Ç–µ—Ä—ã –∏ –∫–∞–∫ –æ–Ω–∏ —Ä–∞–±–æ—Ç–∞—é—Ç?"
    )
    print(f"ü§ñ –û—Ç–≤–µ—Ç: {result1.summary}")
    
    # –í—Ç–æ—Ä–æ–π –∑–∞–ø—Ä–æ—Å —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    print("\nüë§ –ó–∞–ø—Ä–æ—Å 2: –ö–∞–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –ª–∏–¥–∏—Ä—É—é—Ç –≤ —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏?")
    result2 = assistant.process_message_sync(
        "–ö–∞–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –ª–∏–¥–∏—Ä—É—é—Ç –≤ —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏?"
    )
    print(f"ü§ñ –û—Ç–≤–µ—Ç: {result2.summary}")
    
    # –¢—Ä–µ—Ç–∏–π –∑–∞–ø—Ä–æ—Å
    print("\nüë§ –ó–∞–ø—Ä–æ—Å 3: –ö–∞–∫–∏–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç?")
    result3 = assistant.process_message_sync(
        "–ö–∞–∫–∏–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç?"
    )
    print(f"ü§ñ –û—Ç–≤–µ—Ç: {result3.summary}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
    all_orgs = set()
    for result in [result1, result2, result3]:
        all_orgs.update(result.entities.organizations)
    
    print("\nüè¢ –£–ø–æ–º—è–Ω—É—Ç—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏:")
    for org in sorted(all_orgs):
        print(f"  ‚Ä¢ {org}")


async def example_async_multiple_searches():
    """–ü—Ä–∏–º–µ—Ä –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–∏—Å–∫–æ–≤"""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 3: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ–∏—Å–∫–∏")
    print("=" * 60)
    
    assistant = WebResearchAssistant(
        openai_api_key=os.getenv("OPENAI_API_KEY"),
        tavily_api_key=os.getenv("TAVILY_API_KEY")
    )
    
    queries = [
        "Latest breakthroughs in cancer research 2024",
        "Climate change impact on ocean ecosystems",
        "Advances in renewable energy storage technology"
    ]
    
    print("\nüöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –ø–æ–∏—Å–∫–∏...")
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    tasks = []
    for query in queries:
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (—á—Ç–æ–±—ã –Ω–µ —Å–º–µ—à–∏–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã)
        new_assistant = WebResearchAssistant(
            openai_api_key=os.getenv("OPENAI_API_KEY"),
            tavily_api_key=os.getenv("TAVILY_API_KEY")
        )
        tasks.append(new_assistant.process_message(query))
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    results = await asyncio.gather(*tasks)
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    for query, result in zip(queries, results):
        print(f"\nüìå –ó–∞–ø—Ä–æ—Å: {query}")
        print(f"   –†–µ–∑—é–º–µ: {result.summary[:200]}...")
        print(f"   –ù–∞–π–¥–µ–Ω–æ –∫–ª—é—á–µ–≤—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: {len(result.key_findings)}")
        print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.confidence_level}")


def example_export_to_json():
    """–ü—Ä–∏–º–µ—Ä —ç–∫—Å–ø–æ—Ä—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON —Ñ–∞–π–ª"""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 4: –≠–∫—Å–ø–æ—Ä—Ç –≤ JSON")
    print("=" * 60)
    
    assistant = WebResearchAssistant(
        openai_api_key=os.getenv("OPENAI_API_KEY"),
        tavily_api_key=os.getenv("TAVILY_API_KEY")
    )
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
    query = "Artificial Intelligence trends and predictions for 2025"
    print(f"\nüîç –ò—Å—Å–ª–µ–¥—É–µ–º: {query}")
    
    result = assistant.process_message_sync(query)
    
    # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤ JSON —Ñ–∞–π–ª
    output_file = "research_output.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(result.model_dump(), f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–∞
    print("\nüìÑ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞:")
    data = result.model_dump()
    for key in data.keys():
        if isinstance(data[key], list):
            print(f"  ‚Ä¢ {key}: [{len(data[key])} —ç–ª–µ–º–µ–Ω—Ç–æ–≤]")
        elif isinstance(data[key], dict):
            print(f"  ‚Ä¢ {key}: {{{len(data[key])} –ø–æ–ª–µ–π}}")
        else:
            print(f"  ‚Ä¢ {key}: {type(data[key]).__name__}")


def example_domain_specific_research():
    """–ü—Ä–∏–º–µ—Ä –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏"""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 5: –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏")
    print("=" * 60)
    
    assistant = WebResearchAssistant(
        openai_api_key=os.getenv("OPENAI_API_KEY"),
        tavily_api_key=os.getenv("TAVILY_API_KEY")
    )
    
    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å
    tech_query = """
    Compare the performance and features of the latest 
    JavaScript frameworks: React 19, Vue 3.4, and Angular 17. 
    Focus on bundle size, performance benchmarks, and developer experience.
    """
    
    print(f"\nüíª –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑...")
    result = assistant.process_message_sync(tech_query)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüìä –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
    print(f"  ‚Ä¢ –û—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞: {result.categories.main_topic}")
    print(f"  ‚Ä¢ –ü–æ–¥—Ç–µ–º—ã: {', '.join(result.categories.subtopics[:5])}")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –Ω–∞—Ö–æ–¥–∫–∏ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
    high_relevance = [f for f in result.key_findings if f.relevance_score >= 8]
    medium_relevance = [f for f in result.key_findings if 5 <= f.relevance_score < 8]
    
    print(f"\n‚≠ê –í—ã—Å–æ–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å ({len(high_relevance)} –Ω–∞—Ö–æ–¥–æ–∫):")
    for finding in high_relevance[:3]:
        print(f"  ‚Ä¢ {finding.title}")
    
    print(f"\nüìç –°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å ({len(medium_relevance)} –Ω–∞—Ö–æ–¥–æ–∫):")
    for finding in medium_relevance[:2]:
        print(f"  ‚Ä¢ {finding.title}")
    
    # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
    print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —É–≥–ª—É–±–ª–µ–Ω–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è:")
    for i, query in enumerate(result.additional_queries[:3], 1):
        print(f"  {i}. {query}")


def example_analyze_sentiment():
    """–ü—Ä–∏–º–µ—Ä –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    print("\n" + "=" * 60)
    print("–ü–†–ò–ú–ï–† 6: –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
    print("=" * 60)
    
    assistant = WebResearchAssistant(
        openai_api_key=os.getenv("OPENAI_API_KEY"),
        tavily_api_key=os.getenv("TAVILY_API_KEY")
    )
    
    topics = [
        "Electric vehicle market growth 2024",
        "Global economic recession risks",
        "Breakthrough in Alzheimer's treatment"
    ]
    
    sentiments = {"positive": 0, "neutral": 0, "negative": 0}
    
    print("\nüì∞ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ —Ç–µ–º–∞–º:")
    
    for topic in topics:
        result = assistant.process_message_sync(topic)
        sentiments[result.sentiment] += 1
        
        emoji = {"positive": "üòä", "neutral": "üòê", "negative": "üòü"}[result.sentiment]
        print(f"\n  {emoji} {topic}")
        print(f"     –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {result.sentiment}")
        print(f"     –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.confidence_level}")
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏:")
    total = sum(sentiments.values())
    for sentiment, count in sentiments.items():
        percentage = (count / total) * 100
        bar = "‚ñà" * int(percentage / 5)
        print(f"  {sentiment:8}: {bar} {percentage:.0f}%")


# ============================================================================
# –¢–µ—Å—Ç–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
# ============================================================================

def test_structured_output():
    """–¢–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞"""
    print("\n" + "=" * 60)
    print("–¢–ï–°–¢: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –≤—ã–≤–æ–¥–∞")
    print("=" * 60)
    
    assistant = WebResearchAssistant(
        openai_api_key=os.getenv("OPENAI_API_KEY"),
        tavily_api_key=os.getenv("TAVILY_API_KEY")
    )
    
    result = assistant.process_message_sync("Python programming best practices")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –ø–æ–ª–µ–π
    checks = {
        "query": isinstance(result.query, str),
        "timestamp": isinstance(result.timestamp, str),
        "summary": isinstance(result.summary, str) and len(result.summary) > 0,
        "key_findings": isinstance(result.key_findings, list) and len(result.key_findings) > 0,
        "categories": result.categories is not None,
        "entities": result.entities is not None,
        "sentiment": result.sentiment in ["positive", "neutral", "negative"],
        "confidence_level": result.confidence_level in ["high", "medium", "low"],
        "additional_queries": isinstance(result.additional_queries, list)
    }
    
    print("\n‚úîÔ∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:")
    for field, is_valid in checks.items():
        status = "‚úÖ" if is_valid else "‚ùå"
        print(f"  {status} {field}: {'–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ' if is_valid else '–û—à–∏–±–∫–∞'}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é Pydantic
    try:
        json_str = result.model_dump_json()
        print(f"\n‚úÖ JSON –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–π–¥–µ–Ω–∞")
        print(f"   –†–∞–∑–º–µ—Ä JSON: {len(json_str)} —Å–∏–º–≤–æ–ª–æ–≤")
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ JSON –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
    
    return all(checks.values())


# ============================================================================
# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤—Å–µ—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
# ============================================================================

def run_all_examples():
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ –ø—Ä–∏–º–µ—Ä—ã"""
    print("\n" + "üöÄ –ó–ê–ü–£–°–ö –í–°–ï–• –ü–†–ò–ú–ï–†–û–í " + "üöÄ")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–µ–π
    if not os.getenv("OPENAI_API_KEY") or not os.getenv("TAVILY_API_KEY"):
        print("‚ùå –û—à–∏–±–∫–∞: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ OPENAI_API_KEY –∏ TAVILY_API_KEY –≤ —Ñ–∞–π–ª–µ .env")
        return
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
    example_basic_search()
    example_conversation_with_memory()
    example_export_to_json()
    example_domain_specific_research()
    example_analyze_sentiment()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä
    print("\n" + "=" * 60)
    asyncio.run(example_async_multiple_searches())
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    test_structured_output()
    
    print("\n" + "=" * 60)
    print("‚úÖ –í–°–ï –ü–†–ò–ú–ï–†–´ –í–´–ü–û–õ–ù–ï–ù–´ –£–°–ü–ï–®–ù–û!")
    print("=" * 60)


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –ø—Ä–∏–º–µ—Ä—ã
    #run_all_examples()
    
    # –ò–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä:
    example_basic_search()
    # example_conversation_with_memory()
    # asyncio.run(example_async_multiple_searches())