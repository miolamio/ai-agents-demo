#!/usr/bin/env python3
"""
–§–∏–Ω–∞–ª—å–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è RAG –∞–≥–µ–Ω—Ç–æ–≤ - –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –±–µ–∑ –∑–∞–≤–∏—Å–∞–Ω–∏—è
"""

import os
import sys
import time
from dotenv import load_dotenv

load_dotenv()

def show_project_overview():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞"""
    print("üéØ RAG Agent Examples - –§–∏–Ω–∞–ª—å–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è")
    print("=" * 60)
    print("–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É RAG –∞–≥–µ–Ω—Ç–æ–≤ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
    print()
    
    print("üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —Å–æ–¥–µ—Ä–∂–∏—Ç:")
    print("  ‚Ä¢ 6 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")  
    print("  ‚Ä¢ 55 —á–∞–Ω–∫–æ–≤")
    print("  ‚Ä¢ ~47,000 —Å–∏–º–≤–æ–ª–æ–≤")
    print("  ‚Ä¢ 3 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: technical_docs, api_reference, tutorials")
    print()

def analyze_knowledge_base():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
    print("üìä –ê–Ω–∞–ª–∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:")
    print("=" * 30)
    
    knowledge_base_path = os.path.join(os.path.dirname(__file__), "knowledge_base")
    
    if not os.path.exists(knowledge_base_path):
        print("‚ùå –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return False
    
    categories = {
        "technical_docs": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è",
        "api_reference": "API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è", 
        "tutorials": "–ü–æ—à–∞–≥–æ–≤—ã–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞"
    }
    
    total_size = 0
    total_files = 0
    
    for category, description in categories.items():
        category_path = os.path.join(knowledge_base_path, category)
        if os.path.exists(category_path):
            files = [f for f in os.listdir(category_path) if f.endswith('.md')]
            category_size = 0
            
            print(f"\nüìÅ {category} ({description})")
            for file in files:
                file_path = os.path.join(category_path, file)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        file_size = len(content)
                        category_size += file_size
                        print(f"   ‚Ä¢ {file}: {file_size:,} —Å–∏–º–≤–æ–ª–æ–≤")
                except Exception as e:
                    print(f"   ‚Ä¢ {file}: –æ—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è")
            
            total_size += category_size
            total_files += len(files)
            print(f"   –ò—Ç–æ–≥–æ: {len(files)} —Ñ–∞–π–ª–æ–≤, {category_size:,} —Å–∏–º–≤–æ–ª–æ–≤")
    
    print(f"\nüìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total_files}")
    print(f"   ‚Ä¢ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {total_size:,} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {total_size//total_files:,} —Å–∏–º–≤–æ–ª–æ–≤")
    
    return True

def demonstrate_chunking():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("\nüî™ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏—è:")
    print("=" * 35)
    
    try:
        from langchain_community.document_loaders import DirectoryLoader
        from langchain_text_splitters import RecursiveCharacterTextSplitter
        
        knowledge_base_path = os.path.join(os.path.dirname(__file__), "knowledge_base")
        
        print("üìö –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã...")
        loader = DirectoryLoader(knowledge_base_path, glob="**/*.md")
        documents = loader.load()
        
        print("‚úÇÔ∏è  –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏...")
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", " ", ""]
        )
        chunks = text_splitter.split_documents(documents)
        
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç: {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ‚Üí {len(chunks)} —á–∞–Ω–∫–æ–≤")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —á–∞–Ω–∫–æ–≤
        chunk_sizes = [len(chunk.page_content) for chunk in chunks]
        avg_size = sum(chunk_sizes) / len(chunk_sizes)
        min_size = min(chunk_sizes)
        max_size = max(chunk_sizes)
        
        print(f"üìä –†–∞–∑–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤:")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π: {avg_size:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   ‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π: {min_size} —Å–∏–º–≤–æ–ª–æ–≤") 
        print(f"   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π: {max_size} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤
        print(f"\nüìù –ü—Ä–∏–º–µ—Ä—ã —á–∞–Ω–∫–æ–≤:")
        for i, chunk in enumerate(chunks[:3]):
            source = chunk.metadata.get('source', 'unknown').split('/')[-1]
            print(f"   {i+1}. [{source}] {chunk.page_content[:100]}...")
        
        return chunks
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        return []

def show_vector_db_comparison():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ë–î"""
    print("\n‚ö° –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ë–î:")
    print("=" * 35)
    
    comparison_data = {
        "FAISS": {
            "build_time": "4-5 —Å–µ–∫—É–Ω–¥",
            "search_time": "0.6 —Å–µ–∫—É–Ω–¥", 
            "memory": "–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è",
            "setup": "–°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å",
            "scalability": "–û—Ç–ª–∏—á–Ω–∞—è",
            "cost": "–ë–µ—Å–ø–ª–∞—Ç–Ω–æ",
            "best_for": "Production, –±–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ"
        },
        "ChromaDB": {
            "build_time": "2-3 —Å–µ–∫—É–Ω–¥—ã",
            "search_time": "2.5 —Å–µ–∫—É–Ω–¥",
            "memory": "–£–º–µ—Ä–µ–Ω–Ω–∞—è", 
            "setup": "–ü—Ä–æ—Å—Ç–∞—è",
            "scalability": "–•–æ—Ä–æ—à–∞—è",
            "cost": "–ë–µ—Å–ø–ª–∞—Ç–Ω–æ",
            "best_for": "–†–∞–∑—Ä–∞–±–æ—Ç–∫–∞, –ø—Ä–æ—Ç–æ—Ç–∏–ø—ã"
        }
    }
    
    print("üìä –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞:")
    print(f"{'–ú–µ—Ç—Ä–∏–∫–∞':<15} {'FAISS':<15} {'ChromaDB':<15}")
    print("-" * 45)
    print(f"{'–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ':<15} {comparison_data['FAISS']['build_time']:<15} {comparison_data['ChromaDB']['build_time']:<15}")
    print(f"{'–ü–æ–∏—Å–∫':<15} {comparison_data['FAISS']['search_time']:<15} {comparison_data['ChromaDB']['search_time']:<15}")
    print(f"{'–ü–∞–º—è—Ç—å':<15} {comparison_data['FAISS']['memory']:<15} {comparison_data['ChromaDB']['memory']:<15}")
    print(f"{'–ù–∞—Å—Ç—Ä–æ–π–∫–∞':<15} {comparison_data['FAISS']['setup']:<15} {comparison_data['ChromaDB']['setup']:<15}")
    
    print(f"\nüéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print(f"   ‚Ä¢ FAISS: {comparison_data['FAISS']['best_for']}")
    print(f"   ‚Ä¢ ChromaDB: {comparison_data['ChromaDB']['best_for']}")

def show_agent_capabilities():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–æ–≤"""
    print("\nü§ñ –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ RAG –∞–≥–µ–Ω—Ç–æ–≤:")
    print("=" * 35)
    
    agents = {
        "MultiSourceRAGAgent": [
            "–†–∞–±–æ—Ç–∞ —Å 3+ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ –∑–Ω–∞–Ω–∏–π",
            "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤", 
            "–°–∏–Ω—Ç–µ–∑ –æ—Ç–≤–µ—Ç–æ–≤ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤",
            "–ü–∞–º—è—Ç—å —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç",
            "–û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –æ—Ç–≤–µ—Ç–∞—Ö"
        ],
        "SmartRetrievalAgent": [
            "–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤",
            "–ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ —É—Ä–æ–≤–Ω—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è",
            "–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏",
            "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤",
            "–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
        ]
    }
    
    for agent_name, capabilities in agents.items():
        print(f"\nüîß {agent_name}:")
        for capability in capabilities:
            print(f"   ‚úì {capability}")

def show_example_interactions():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π"""
    print("\nüí¨ –ü—Ä–∏–º–µ—Ä—ã –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π:")
    print("=" * 35)
    
    examples = [
        {
            "level": "–ù–∞—á–∏–Ω–∞—é—â–∏–π",
            "query": "–ß—Ç–æ —Ç–∞–∫–æ–µ –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö?",
            "response": "–í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö - —ç—Ç–æ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –ø–æ–∏—Å–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –¥–∞–Ω–Ω—ã—Ö. –û–Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ AI-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö...",
            "sources": ["technical_docs/vector_databases.md"]
        },
        {
            "level": "–°—Ä–µ–¥–Ω–∏–π", 
            "query": "–ö–∞–∫ —Å–æ–∑–¥–∞—Ç—å FAISS –∏–Ω–¥–µ–∫—Å —Å –ø–æ–º–æ—â—å—é LangChain?",
            "response": "–î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è FAISS –∏–Ω–¥–µ–∫—Å–∞: 1) –°–æ–∑–¥–∞–π—Ç–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å OpenAIEmbeddings, 2) –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ FAISS.from_documents(chunks, embeddings), 3) –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ —Å vectorstore.save_local()...",
            "sources": ["api_reference/faiss_chroma_api.md", "api_reference/langchain_api.md"]
        },
        {
            "level": "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π",
            "query": "–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≤ RAG",
            "response": "–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π (–≤–µ–∫—Ç–æ—Ä–Ω—ã–π) –∏ –ª–µ–∫—Å–∏—á–µ—Å–∫–∏–π (BM25) –ø–æ–∏—Å–∫. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ EnsembleRetriever —Å –≤–µ—Å–∞–º–∏ [0.4, 0.6] –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –±–∞–ª–∞–Ω—Å–∞...",
            "sources": ["tutorials/advanced_rag_techniques.md"]
        }
    ]
    
    for i, example in enumerate(examples, 1):
        print(f"\n{i}. üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ({example['level']}):")
        print(f"   ü§î \"{example['query']}\"")
        print(f"   ü§ñ {example['response'][:100]}...")
        print(f"   üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join([s.split('/')[-1] for s in example['sources']])}")

def show_usage_modes():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∂–∏–º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    print("\nüöÄ –†–µ–∂–∏–º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:")
    print("=" * 30)
    
    modes = [
        ("quick_demo.py", "–ë—ã—Å—Ç—Ä–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –±–µ–∑ API", "‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç –≤—Å–µ–≥–¥–∞"),
        ("rag_agent_examples.py", "–ü–æ–ª–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è", "‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç OpenAI API"),
        ("rag_agent_examples.py multi", "–ú—É–ª—å—Ç–∏-–∏—Å—Ç–æ—á–Ω–∏–∫–∏", "‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç OpenAI API"),
        ("rag_agent_examples.py smart", "–£–º–Ω—ã–π –ø–æ–∏—Å–∫", "‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç OpenAI API"),
        ("rag_agent_examples.py compare", "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ë–î", "‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç OpenAI API"),
        ("rag_agent_examples.py chat", "–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Ç", "‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç OpenAI API")
    ]
    
    print("üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:")
    for command, description, status in modes:
        print(f"   ‚Ä¢ python {command}")
        print(f"     {description} {status}")
        print()

def show_technical_details():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏"""
    print("üõ† –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏:")
    print("=" * 25)
    
    details = {
        "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞": [
            "DirectoryLoader ‚Üí RecursiveCharacterTextSplitter ‚Üí OpenAI Embeddings ‚Üí FAISS/ChromaDB ‚Üí RetrievalQA ‚Üí ChatOpenAI"
        ],
        "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —á–∞–Ω–∫–∏—Ä–æ–≤–∞–Ω–∏—è": [
            "–†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞: 1000 —Å–∏–º–≤–æ–ª–æ–≤",
            "–ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ: 200 —Å–∏–º–≤–æ–ª–æ–≤", 
            "–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏: \\n\\n, \\n, –ø—Ä–æ–±–µ–ª"
        ],
        "–ú–æ–¥–µ–ª–∏": [
            "–≠–º–±–µ–¥–¥–∏–Ω–≥–∏: text-embedding-ada-002 (1536 dim)",
            "LLM: GPT-4 (—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ 0.1, –º–∞–∫—Å —Ç–æ–∫–µ–Ω–æ–≤ 2000)"
        ],
        "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏": [
            "–¢–∞–π–º–∞—É—Ç—ã: 30—Å –Ω–∞ –∑–∞–ø—Ä–æ—Å",
            "–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫: try/catch —Å fallback",
            "–ü–∞–º—è—Ç—å: ConversationBufferMemory"
        ]
    }
    
    for category, items in details.items():
        print(f"\nüîß {category}:")
        for item in items:
            print(f"   ‚Ä¢ {item}")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    start_time = time.time()
    
    show_project_overview()
    
    if analyze_knowledge_base():
        chunks = demonstrate_chunking()
        show_vector_db_comparison()
        show_agent_capabilities()
        show_example_interactions()
        show_usage_modes()
        show_technical_details()
        
        elapsed_time = time.time() - start_time
        
        print(f"\nüéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed_time:.1f} —Å–µ–∫—É–Ω–¥")
        print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(chunks) if chunks else 0} —á–∞–Ω–∫–æ–≤")
        
        print(f"\nüìñ –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏:")
        print(f"   ‚Ä¢ –ß–∏—Ç–∞–π—Ç–µ README.md")
        print(f"   ‚Ä¢ –ò–∑—É—á–∞–π—Ç–µ –∫–æ–¥ –≤ rag_agent_examples.py")
        print(f"   ‚Ä¢ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å quick_demo.py")
        
        print(f"\nüöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print(f"   1. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ OPENAI_API_KEY –¥–ª—è –ø–æ–ª–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
        print(f"   2. –î–æ–±–∞–≤—å—Ç–µ —Å–≤–æ–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ knowledge_base/")
        print(f"   3. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏")
        print(f"   4. –°–æ–∑–¥–∞–π—Ç–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å")
        
    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é")

if __name__ == "__main__":
    main()
