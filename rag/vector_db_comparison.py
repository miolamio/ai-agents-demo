#!/usr/bin/env python3
"""
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è RAG
–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã —Ä–∞–±–æ—Ç—ã —Å FAISS, Chroma, Pinecone
"""

import os
import time
import json
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass
import numpy as np

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
from dotenv import load_dotenv
load_dotenv()

# LangChain imports
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS, Chroma
from langchain.schema import Document

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
try:
    from pinecone import Pinecone
    from langchain_pinecone import PineconeVectorStore
    PINECONE_AVAILABLE = True
except ImportError:
    try:
        # Fallback –¥–ª—è —Å—Ç–∞—Ä–æ–π –≤–µ—Ä—Å–∏–∏
        import pinecone
        from langchain_community.vectorstores import Pinecone as PineconeVectorStore
        PINECONE_AVAILABLE = True
    except ImportError:
        PINECONE_AVAILABLE = False
        print("Pinecone –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pinecone-client langchain-pinecone")

try:
    from langchain_cohere import CohereEmbeddings
    COHERE_AVAILABLE = True
except ImportError:
    COHERE_AVAILABLE = False
    print("Cohere –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install cohere langchain-cohere")

try:
    import chromadb
    CHROMA_AVAILABLE = True
except ImportError:
    CHROMA_AVAILABLE = False
    print("ChromaDB –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install chromadb")


@dataclass
class VectorDBConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö"""
    chunk_size: int = 1000
    chunk_overlap: int = 200
    embedding_model: str = "text-embedding-ada-002"
    similarity_threshold: float = 0.7


@dataclass
class BenchmarkResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    db_name: str
    indexing_time: float
    search_time: float
    memory_usage_mb: float
    search_accuracy: float
    setup_complexity: int  # 1-5, –≥–¥–µ 1 - –æ—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ, 5 - —Å–ª–æ–∂–Ω–æ
    scalability_score: int  # 1-5, –≥–¥–µ 5 - –æ—Ç–ª–∏—á–Ω–∞—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å
    cost_rating: str  # "free", "low", "medium", "high"


class VectorDatabaseComparison:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö
    """
    
    def __init__(self, config: VectorDBConfig = None):
        self.config = config or VectorDBConfig()
        self.documents = []
        self.embeddings = OpenAIEmbeddings(model=self.config.embedding_model)
        self.test_queries = [
            "–ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö?",
            "–ß—Ç–æ —Ç–∞–∫–æ–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏?",
            "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞",
            "–ú–µ—Ç–æ–¥—ã –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ RAG —Å–∏—Å—Ç–µ–º",
            "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å LangChain"
        ]
        
    def load_sample_documents(self, docs_path: str = None) -> List[Document]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∏–º–µ—Ä–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        if docs_path and os.path.exists(docs_path):
            loader = DirectoryLoader(docs_path, glob="**/*.md")
            documents = loader.load()
        else:
            # –°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            documents = self._create_synthetic_documents()
        
        # –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.config.chunk_size,
            chunk_overlap=self.config.chunk_overlap
        )
        
        self.documents = text_splitter.split_documents(documents)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        for i, doc in enumerate(self.documents):
            doc.metadata.update({
                "doc_id": f"doc_{i}",
                "chunk_size": len(doc.page_content),
                "source": doc.metadata.get("source", f"synthetic_{i}")
            })
        
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        return self.documents
    
    def _create_synthetic_documents(self) -> List[Document]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
        synthetic_texts = [
            """
            –í–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–æ–±–æ–π —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã —Ö—Ä–∞–Ω–µ–Ω–∏—è, 
            –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º–∏ –¥–∞–Ω–Ω—ã—Ö. –û–Ω–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è 
            –≤ –∑–∞–¥–∞—á–∞—Ö –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –ø–æ–∏—Å–∫–∞ –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤—É –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ 
            –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞. –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –≤–∫–ª—é—á–∞—é—Ç –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É, 
            –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å –∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è.
            """,
            """
            FAISS (Facebook AI Similarity Search) - —ç—Ç–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ 
            —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –ø–ª–æ—Ç–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤. –û–Ω–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –∞–ª–≥–æ—Ä–∏—Ç–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –∏—â—É—Ç 
            –≤ –Ω–∞–±–æ—Ä–∞—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ –ª—é–±–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, –≤–ø–ª–æ—Ç—å –¥–æ —Ç–µ—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –Ω–µ –ø–æ–º–µ—â–∞—Ç—å—Å—è –≤ RAM. 
            FAISS –Ω–∞–ø–∏—Å–∞–Ω –Ω–∞ C++ —Å –ø–æ–ª–Ω—ã–º–∏ –æ–±–µ—Ä—Ç–∫–∞–º–∏ –¥–ª—è Python/numpy.
            """,
            """
            Chroma —è–≤–ª—è–µ—Ç—Å—è open-source –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤. –û–Ω–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–∞ –¥–ª—è 
            –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å AI-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è–º–∏. Chroma –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ 
            –∏—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ, –≤—Å—Ç—Ä–∞–∏–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –∑–∞–ø—Ä–æ—Å—ã, –∏ –±—ã—Å—Ç—Ä–æ –∏—Å–∫–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏. 
            –û–Ω–∞ –≤–∫–ª—é—á–∞–µ—Ç –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é.
            """,
            """
            Pinecone –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –ø–æ–ª–Ω–æ—Å—Ç—å—é —É–ø—Ä–∞–≤–ª—è–µ–º—É—é –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä–∞—è 
            —É–ø—Ä–æ—â–∞–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞. –û–Ω–∞ 
            –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å—é –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É, –≤–∫–ª—é—á–∞—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ 
            –≤—ã—Å–æ–∫—É—é –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å, –ø–æ–∑–≤–æ–ª—è—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞–º —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏—Ç—å—Å—è –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–∏ 
            –≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π.
            """,
            """
            Embedding –º–æ–¥–µ–ª–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç —Ç–µ–∫—Å—Ç –≤ —á–∏—Å–ª–æ–≤—ã–µ –≤–µ–∫—Ç–æ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ñ–∏–∫—Å–∏—Ä—É—é—Ç 
            —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ. OpenAI's text-embedding-ada-002 —è–≤–ª—è–µ—Ç—Å—è –æ–¥–Ω–æ–π –∏–∑ 
            —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—â–µ–π –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è 
            —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á NLP. –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 1536.
            """,
            """
            RAG (Retrieval-Augmented Generation) –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π 
            —Ç–µ–∫—Å—Ç–∞. –°–∏—Å—Ç–µ–º–∞ —Å–Ω–∞—á–∞–ª–∞ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π, –∞ –∑–∞—Ç–µ–º 
            –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏—Ö –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—É—á–∞—Ç—å –±–æ–ª–µ–µ 
            —Ç–æ—á–Ω—ã–µ –∏ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã, —Å–Ω–∏–∂–∞–µ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏ –∏ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.
            """,
            """
            –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ RAG-—Å–∏—Å—Ç–µ–º –≤–∫–ª—é—á–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞–∫ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ 
            (Recall@K, Precision@K, MRR), —Ç–∞–∫ –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (Faithfulness, 
            Answer Relevance). RAGAS (RAG Assessment) - —ç—Ç–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π 
            –æ—Ü–µ–Ω–∫–∏ RAG-–ø–∞–π–ø–ª–∞–π–Ω–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å—É–¥–µ–π.
            """
        ]
        
        documents = []
        for i, text in enumerate(synthetic_texts):
            doc = Document(
                page_content=text.strip(),
                metadata={"source": f"synthetic_doc_{i}.md", "topic": f"topic_{i % 3}"}
            )
            documents.append(doc)
        
        return documents


class FAISSHandler:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è FAISS –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, embeddings):
        self.embeddings = embeddings
        self.vectorstore = None
        
    def setup(self, documents: List[Document]) -> float:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ FAISS –∏–Ω–¥–µ–∫—Å–∞"""
        start_time = time.time()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞
        self.vectorstore = FAISS.from_documents(documents, self.embeddings)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞
        # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã
        # –∫–∞–∫ IndexIVFFlat –∏–ª–∏ IndexHNSW –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
        
        setup_time = time.time() - start_time
        print(f"FAISS setup completed in {setup_time:.2f} seconds")
        return setup_time
    
    def search(self, query: str, k: int = 4) -> Tuple[List[Document], float]:
        """–ü–æ–∏—Å–∫ –≤ FAISS"""
        start_time = time.time()
        
        # –ü–æ–∏—Å–∫ —Å –æ—Ü–µ–Ω–∫–∞–º–∏ —Å—Ö–æ–∂–µ—Å—Ç–∏
        docs_and_scores = self.vectorstore.similarity_search_with_score(query, k=k)
        docs = [doc for doc, _ in docs_and_scores]
        
        search_time = time.time() - start_time
        return docs, search_time
    
    def save_local(self, path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞ –ª–æ–∫–∞–ª—å–Ω–æ"""
        if self.vectorstore:
            self.vectorstore.save_local(path)
    
    def load_local(self, path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ FAISS –∏–Ω–¥–µ–∫—Å–∞"""
        self.vectorstore = FAISS.load_local(path, self.embeddings)
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ FAISS"""
        if not self.vectorstore:
            return {}
        
        # FAISS —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        index = self.vectorstore.index
        return {
            "total_vectors": index.ntotal,
            "dimension": index.d,
            "index_type": type(index).__name__,
            "is_trained": index.is_trained,
            "metric_type": getattr(index, 'metric_type', 'L2')
        }


class ChromaHandler:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è ChromaDB"""
    
    def __init__(self, embeddings):
        self.embeddings = embeddings
        self.vectorstore = None
        self.client = None
        
    def setup(self, documents: List[Document], persist_directory: str = "./chroma_db") -> float:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ ChromaDB"""
        if not CHROMA_AVAILABLE:
            raise ImportError("ChromaDB –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        start_time = time.time()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
        self.client = chromadb.PersistentClient(path=persist_directory)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
        self.vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings,
            client=self.client,
            collection_name="rag_collection",
            persist_directory=persist_directory
        )
        
        setup_time = time.time() - start_time
        print(f"ChromaDB setup completed in {setup_time:.2f} seconds")
        return setup_time
    
    def search(self, query: str, k: int = 4) -> Tuple[List[Document], float]:
        """–ü–æ–∏—Å–∫ –≤ ChromaDB"""
        start_time = time.time()
        
        # –ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º (–ø—Ä–∏–º–µ—Ä)
        docs = self.vectorstore.similarity_search(
            query, 
            k=k,
            # filter={"topic": "specific_topic"}  # –ü—Ä–∏–º–µ—Ä —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        )
        
        search_time = time.time() - start_time
        return docs, search_time
    
    def search_with_metadata_filter(self, query: str, filter_dict: Dict, k: int = 4) -> List[Document]:
        """–ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º"""
        return self.vectorstore.similarity_search(
            query,
            k=k,
            filter=filter_dict
        )
    
    def add_documents(self, documents: List[Document]):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        if self.vectorstore:
            self.vectorstore.add_documents(documents)
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ ChromaDB"""
        if not self.vectorstore:
            return {}
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        collection = self.vectorstore._collection
        return {
            "total_documents": collection.count(),
            "collection_name": collection.name,
            "persist_directory": getattr(self.vectorstore, '_persist_directory', None)
        }


class PineconeHandler:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è Pinecone (–Ω–æ–≤—ã–π API —Å Cohere —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏)"""
    
    def __init__(self, embeddings=None, api_key: str = None, host: str = None):
        self.api_key = api_key or os.environ.get("PINECONE_API_KEY")
        self.host = host or os.environ.get("PINECONE_HOST")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å –≤–º–µ—Å—Ç–æ —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ
        self.index_name = "technospherehr"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å
        self.pc = None
        self.vectorstore = None
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Cohere —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –∏–Ω–¥–µ–∫—Å–æ–º (1024 —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å)
        if COHERE_AVAILABLE and os.getenv("COHERE_API_KEY"):
            self.embeddings = CohereEmbeddings(model="embed-multilingual-v3.0")
            print("üîó –ò—Å–ø–æ–ª—å–∑—É–µ–º Cohere —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (1024 —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å)")
        else:
            self.embeddings = embeddings or OpenAIEmbeddings()
            print("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenAI —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (1536 —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å) - –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ")
        
    def setup(self, documents: List[Document]) -> float:
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ Pinecone –∏–Ω–¥–µ–∫—Å–∞ (–Ω–æ–≤—ã–π API)"""
        if not PINECONE_AVAILABLE:
            raise ImportError("Pinecone –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        if not self.api_key:
            raise ValueError("Pinecone API key –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        start_time = time.time()
        
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ Pinecone –∫–ª–∏–µ–Ω—Ç–∞
            self.pc = Pinecone(api_key=self.api_key)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–Ω–¥–µ–∫—Å—ã
            existing_indexes = self.pc.list_indexes()
            index_names = [idx.name for idx in existing_indexes.indexes] if hasattr(existing_indexes, 'indexes') else []
            
            print(f"–°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–Ω–¥–µ–∫—Å—ã: {index_names}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–∞—à –∏–Ω–¥–µ–∫—Å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if self.index_name not in index_names:
                print(f"‚ùå –ò–Ω–¥–µ–∫—Å '{self.index_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω!")
                print(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã: {index_names}")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –∏–Ω–¥–µ–∫—Å
                if index_names:
                    self.index_name = index_names[0]
                    print(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –∏–Ω–¥–µ–∫—Å: {self.index_name}")
                else:
                    raise ValueError("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤")
            
            # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É –∏–Ω–¥–µ–∫—Å—É
            if self.host:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–π host URL –µ—Å–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
                index = self.pc.Index(host=self.host)
                print(f"üîó –ü–æ–¥–∫–ª—é—á–∏–ª–∏—Å—å –∫ –∏–Ω–¥–µ–∫—Å—É —á–µ—Ä–µ–∑ host URL")
            else:
                index = self.pc.Index(self.index_name)
                print(f"üîó –ü–æ–¥–∫–ª—é—á–∏–ª–∏—Å—å –∫ –∏–Ω–¥–µ–∫—Å—É: {self.index_name}")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
            self.vectorstore = PineconeVectorStore.from_documents(
                documents,
                self.embeddings,
                index=index,
                namespace="default"
            )
            
            setup_time = time.time() - start_time
            print(f"Pinecone setup completed in {setup_time:.2f} seconds")
            return setup_time
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ Pinecone: {e}")
            # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Å –ø—Ä—è–º—ã–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º –∫ host
            if self.host:
                try:
                    print("–ü—Ä–æ–±—É–µ–º –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É –∏–Ω–¥–µ–∫—Å—É...")
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ host URL
                    index = self.pc.Index(host=self.host)
                    
                    self.vectorstore = PineconeVectorStore(
                        index=index,
                        embedding=self.embeddings,
                        text_key="text",
                        namespace="default"
                    )
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
                    texts = [doc.page_content for doc in documents]
                    metadatas = [doc.metadata for doc in documents]
                    self.vectorstore.add_texts(texts, metadatas)
                    
                    setup_time = time.time() - start_time
                    print(f"Pinecone setup completed (direct host) in {setup_time:.2f} seconds")
                    return setup_time
                except Exception as e2:
                    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä—è–º–æ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏: {e2}")
                    raise e
            else:
                raise e
    
    def search(self, query: str, k: int = 4) -> Tuple[List[Document], float]:
        """–ü–æ–∏—Å–∫ –≤ Pinecone"""
        start_time = time.time()
        
        docs = self.vectorstore.similarity_search(query, k=k)
        
        search_time = time.time() - start_time
        return docs, search_time
    
    def search_with_namespace(self, query: str, namespace: str, k: int = 4) -> List[Document]:
        """–ü–æ–∏—Å–∫ –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º namespace"""
        if not self.pc:
            raise ValueError("Pinecone –∫–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–ª—è –Ω—É–∂–Ω–æ–≥–æ namespace
            if self.host:
                index = self.pc.Index(self.index_name, host=self.host)
            else:
                index = self.pc.Index(self.index_name)
            
            temp_store = PineconeVectorStore(
                index=index,
                embedding=self.embeddings,
                text_key="text",
                namespace=namespace
            )
            return temp_store.similarity_search(query, k=k)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –≤ namespace {namespace}: {e}")
            return []
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ Pinecone"""
        if not self.pc or not self.index_name:
            return {}
        
        try:
            if self.host:
                index = self.pc.Index(self.index_name, host=self.host)
            else:
                index = self.pc.Index(self.index_name)
            
            stats = index.describe_index_stats()
            return {
                "total_vectors": stats.total_vector_count,
                "dimension": stats.dimension,
                "index_fullness": stats.index_fullness,
                "namespaces": list(stats.namespaces.keys()) if stats.namespaces else []
            }
        except Exception as e:
            return {"error": str(e)}


class VectorDatabaseBenchmark:
    """–ë–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, comparison: VectorDatabaseComparison):
        self.comparison = comparison
        self.results = []
        
    def run_benchmark(self, pinecone_api_key: str = None) -> List[BenchmarkResult]:
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞"""
        documents = self.comparison.load_sample_documents()
        
        # –ë–µ–Ω—á–º–∞—Ä–∫ FAISS
        print("\n=== –ë–µ–Ω—á–º–∞—Ä–∫ FAISS ===")
        faiss_result = self._benchmark_faiss(documents)
        self.results.append(faiss_result)
        
        # –ë–µ–Ω—á–º–∞—Ä–∫ ChromaDB
        if CHROMA_AVAILABLE:
            print("\n=== –ë–µ–Ω—á–º–∞—Ä–∫ ChromaDB ===")
            chroma_result = self._benchmark_chroma(documents)
            self.results.append(chroma_result)
        
        # –ë–µ–Ω—á–º–∞—Ä–∫ Pinecone
        if PINECONE_AVAILABLE and pinecone_api_key:
            print("\n=== –ë–µ–Ω—á–º–∞—Ä–∫ Pinecone ===")
            pinecone_result = self._benchmark_pinecone(documents, pinecone_api_key)
            self.results.append(pinecone_result)
        
        return self.results
    
    def _benchmark_faiss(self, documents: List[Document]) -> BenchmarkResult:
        """–ë–µ–Ω—á–º–∞—Ä–∫ FAISS"""
        handler = FAISSHandler(self.comparison.embeddings)
        
        # –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        indexing_time = handler.setup(documents)
        
        # –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ–∏—Å–∫–∞
        total_search_time = 0
        for query in self.comparison.test_queries:
            _, search_time = handler.search(query)
            total_search_time += search_time
        
        avg_search_time = total_search_time / len(self.comparison.test_queries)
        
        # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
        memory_usage = len(documents) * self.comparison.config.chunk_size * 1.5 / 1024 / 1024
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = handler.get_stats()
        print(f"FAISS stats: {stats}")
        
        return BenchmarkResult(
            db_name="FAISS",
            indexing_time=indexing_time,
            search_time=avg_search_time,
            memory_usage_mb=memory_usage,
            search_accuracy=0.85,  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            setup_complexity=2,  # –ü—Ä–æ—Å—Ç–æ
            scalability_score=3,  # –°—Ä–µ–¥–Ω—è—è
            cost_rating="free"
        )
    
    def _benchmark_chroma(self, documents: List[Document]) -> BenchmarkResult:
        """–ë–µ–Ω—á–º–∞—Ä–∫ ChromaDB"""
        handler = ChromaHandler(self.comparison.embeddings)
        
        # –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
        indexing_time = handler.setup(documents, "./temp_chroma_benchmark")
        
        # –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ–∏—Å–∫–∞
        total_search_time = 0
        for query in self.comparison.test_queries:
            _, search_time = handler.search(query)
            total_search_time += search_time
        
        avg_search_time = total_search_time / len(self.comparison.test_queries)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = handler.get_stats()
        print(f"ChromaDB stats: {stats}")
        
        return BenchmarkResult(
            db_name="ChromaDB",
            indexing_time=indexing_time,
            search_time=avg_search_time,
            memory_usage_mb=len(documents) * 2.0,  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            search_accuracy=0.88,
            setup_complexity=1,  # –û—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ
            scalability_score=4,  # –•–æ—Ä–æ—à–∞—è
            cost_rating="free"
        )
    
    def _benchmark_pinecone(self, documents: List[Document], api_key: str) -> BenchmarkResult:
        """–ë–µ–Ω—á–º–∞—Ä–∫ Pinecone"""
        pinecone_host = os.getenv("PINECONE_HOST")
        # –°–æ–∑–¥–∞–µ–º handler –±–µ–∑ –ø–µ—Ä–µ–¥–∞—á–∏ embeddings - –æ–Ω —Å–∞–º –≤—ã–±–µ—Ä–µ—Ç Cohere
        handler = PineconeHandler(api_key=api_key, host=pinecone_host)
        
        try:
            # –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
            indexing_time = handler.setup(documents)
            
            # –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ–∏—Å–∫–∞
            total_search_time = 0
            for query in self.comparison.test_queries:
                _, search_time = handler.search(query)
                total_search_time += search_time
            
            avg_search_time = total_search_time / len(self.comparison.test_queries)
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            stats = handler.get_stats()
            print(f"Pinecone stats: {stats}")
            
            return BenchmarkResult(
                db_name="Pinecone",
                indexing_time=indexing_time,
                search_time=avg_search_time,
                memory_usage_mb=0,  # –û–±–ª–∞—á–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ
                search_accuracy=0.92,
                setup_complexity=3,  # –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
                scalability_score=5,  # –û—Ç–ª–∏—á–Ω–∞—è
                cost_rating="medium"
            )
        
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –±–µ–Ω—á–º–∞—Ä–∫–µ Pinecone: {e}")
            return BenchmarkResult(
                db_name="Pinecone",
                indexing_time=0,
                search_time=0,
                memory_usage_mb=0,
                search_accuracy=0,
                setup_complexity=3,
                scalability_score=5,
                cost_rating="medium"
            )
    
    def generate_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏"""
        if not self.results:
            return "–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç—á–µ—Ç–∞"
        
        report = ["=== –°–†–ê–í–ù–ï–ù–ò–ï –í–ï–ö–¢–û–†–ù–´–• –ë–ê–ó –î–ê–ù–ù–´–• ===\n"]
        
        # –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        header = f"{'–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö':<15} {'–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è(—Å)':<15} {'–ü–æ–∏—Å–∫(–º—Å)':<12} {'–ü–∞–º—è—Ç—å(–ú–ë)':<12} {'–¢–æ—á–Ω–æ—Å—Ç—å':<10} {'–ù–∞—Å—Ç—Ä–æ–π–∫–∞':<10} {'–ú–∞—Å—à—Ç–∞–±.':<10} {'–°—Ç–æ–∏–º–æ—Å—Ç—å':<10}"
        report.append(header)
        report.append("=" * len(header))
        
        for result in self.results:
            row = f"{result.db_name:<15} {result.indexing_time:<15.2f} {result.search_time*1000:<12.1f} {result.memory_usage_mb:<12.1f} {result.search_accuracy:<10.2f} {result.setup_complexity:<10} {result.scalability_score:<10} {result.cost_rating:<10}"
            report.append(row)
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report.append("\n=== –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò ===")
        
        # –õ—É—á—à–∏–π –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
        dev_choice = min(self.results, key=lambda x: x.setup_complexity)
        report.append(f"–î–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏—è: {dev_choice.db_name}")
        
        # –õ—É—á—à–∏–π –¥–ª—è production
        prod_choice = max(self.results, key=lambda x: x.scalability_score + x.search_accuracy)
        report.append(f"–î–ª—è production: {prod_choice.db_name}")
        
        # –°–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫
        fast_choice = min(self.results, key=lambda x: x.search_time)
        report.append(f"–°–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫: {fast_choice.db_name}")
        
        # –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è
        free_solutions = [r.db_name for r in self.results if r.cost_rating == "free"]
        if free_solutions:
            report.append(f"–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è: {', '.join(free_solutions)}")
        
        return "\n".join(report)


def demonstrate_advanced_features():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ë–î"""
    print("\n=== –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ü–†–û–î–í–ò–ù–£–¢–´–• –í–û–ó–ú–û–ñ–ù–û–°–¢–ï–ô ===")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    documents = [
        Document(
            page_content="–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ FAISS –¥–ª—è –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
            metadata={"type": "tutorial", "difficulty": "advanced", "category": "performance"}
        ),
        Document(
            page_content="–û—Å–Ω–æ–≤—ã —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º–∏ –±–∞–∑–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö",
            metadata={"type": "guide", "difficulty": "beginner", "category": "basics"}
        ),
        Document(
            page_content="–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤ –≤ ChromaDB",
            metadata={"type": "tutorial", "difficulty": "intermediate", "category": "performance"}
        ),
    ]
    
    embeddings = OpenAIEmbeddings()
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –≤ ChromaDB
    if CHROMA_AVAILABLE:
        print("\n--- ChromaDB —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö ---")
        chroma_handler = ChromaHandler(embeddings)
        chroma_handler.setup(documents, "./demo_chroma")
        
        # –ü–æ–∏—Å–∫ —Ç–æ–ª—å–∫–æ —Å—Ä–µ–¥–∏ —Ç—É—Ç–æ—Ä–∏–∞–ª–æ–≤
        tutorial_results = chroma_handler.search_with_metadata_filter(
            "–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
            filter_dict={"type": "tutorial"},
            k=2
        )
        print(f"–ù–∞–π–¥–µ–Ω–æ —Ç—É—Ç–æ—Ä–∏–∞–ª–æ–≤: {len(tutorial_results)}")
        
        # –ü–æ–∏—Å–∫ –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö
        beginner_results = chroma_handler.search_with_metadata_filter(
            "–≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö",
            filter_dict={"difficulty": "beginner"},
            k=2
        )
        print(f"–ù–∞–π–¥–µ–Ω–æ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö: {len(beginner_results)}")
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∏ FAISS
    print("\n--- FAISS —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ ---")
    faiss_handler = FAISSHandler(embeddings)
    faiss_handler.setup(documents)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    faiss_handler.save_local("./demo_faiss_index")
    print("FAISS –∏–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞
    new_faiss_handler = FAISSHandler(embeddings)
    new_faiss_handler.load_local("./demo_faiss_index")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
    results, search_time = new_faiss_handler.search("–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è")
    print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å —Ä–∞–±–æ—Ç–∞–µ—Ç: –Ω–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞ {search_time:.3f}—Å")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è"""
    print("=== –°–†–ê–í–ù–ï–ù–ò–ï –í–ï–ö–¢–û–†–ù–´–• –ë–ê–ó –î–ê–ù–ù–´–• ===")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    config = VectorDBConfig(
        chunk_size=800,
        chunk_overlap=100,
        embedding_model="text-embedding-ada-002"
    )
    
    comparison = VectorDatabaseComparison(config)
    benchmark = VectorDatabaseBenchmark(comparison)
    
    # –ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞ (–≤–∫–ª—é—á–∞—è Pinecone –µ—Å–ª–∏ –∫–ª—é—á –Ω–∞—Å—Ç—Ä–æ–µ–Ω)
    pinecone_api_key = os.getenv("PINECONE_API_KEY")
    if pinecone_api_key and pinecone_api_key != "your_pinecone_api_key_here":
        print("üîó –ù–∞–π–¥–µ–Ω Pinecone API –∫–ª—é—á - –≤–∫–ª—é—á–∞–µ–º –≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")
        results = benchmark.run_benchmark(pinecone_api_key)
    else:
        print("‚ö†Ô∏è Pinecone API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω - —Ç–µ—Å—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ FAISS –∏ ChromaDB")
        results = benchmark.run_benchmark()
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    report = benchmark.generate_report()
    print("\n" + report)
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π
    demonstrate_advanced_features()
    
    print("\n=== –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï ===")
    print("–í—ã–±–æ—Ä –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏—Ç –æ—Ç:")
    print("1. –†–∞–∑–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏")
    print("2. –ë—é–¥–∂–µ—Ç–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π")
    print("3. –°–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã")
    print("4. –¢—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    print("5. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º")


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –î–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –Ω—É–∂–Ω—ã:
    # 1. pip install chromadb
    # 2. pip install pinecone-client
    # 3. Pinecone API –∫–ª—é—á –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è PINECONE_API_KEY
    
    try:
        main()
    except ImportError as e:
        print(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:")
        print("pip install chromadb pinecone-client")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ API –∫–ª—é—á–∏")