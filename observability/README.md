# Примеры кода для 7-го занятия
## Производственная эксплуатация LLM агентов

Этот каталог содержит практические примеры кода, демонстрирующие ключевые инструменты и техники для промышленной эксплуатации агентов на основе больших языковых моделей.

## 🚀 Быстрая настройка

### 1. Подготовка переменных окружения
```bash
# Скопируйте файл с примерами переменных
cp env.example .env

# Отредактируйте .env и заполните ваши API ключи
nano .env
```

### 2. Установка зависимостей
```bash
pip install -r requirements.txt
```

### 3. Запуск LangFuse (опционально)
```bash
# Для self-hosted мониторинга
docker-compose -f docker-compose.langfuse.yml up -d

# Откройте http://localhost:3000 и создайте проект
# Добавьте полученные ключи в .env
```

## 📁 Структура примеров

### 1. [example1_langsmith_tracing.py](example1_langsmith_tracing.py)
**Базовая трассировка с LangSmith**
- Инициализация клиента LangSmith
- Создание иерархических трассировок
- Логирование входных/выходных данных
- Настройка метаданных и тегов для отладки

### 2. [example2_dspy_optimization.py](example2_dspy_optimization.py)  
**DSPy программа с автоматической оптимизацией**
- Определение сигнатур задач
- Создание модулей DSPy
- Компиляция с различными оптимизаторами
- Сравнение до и после оптимизации

### 3. [example3_langfuse_monitoring.py](example3_langfuse_monitoring.py)
**LangFuse для open-source мониторинга**
- Self-hosted решение для трассировки
- Независимость от конкретных фреймворков
- Интеграция с OpenTelemetry
- Анализ стоимости и производительности

### 4. [example4_litellm_cost_control.py](example4_litellm_cost_control.py)
**LiteLLM для контроля затрат**
- Унифицированный API для 100+ моделей
- Интеллектуальная маршрутизация по стоимости
- Семантическое кэширование запросов
- Пакетирование со скидками до 50%

## 🚀 Быстрый запуск

### Установка зависимостей
```bash
pip install -r requirements.txt
```

### Настройка переменных окружения
```bash
# Используйте файл env.example как шаблон
cp env.example .env

# Основные переменные для начала работы:
# Для LangSmith (example1)
export LANGCHAIN_API_KEY="your-langsmith-key"
export LANGCHAIN_TRACING_V2=true

# Для LangFuse (example3) 
export LANGFUSE_HOST="http://localhost:3000"
export LANGFUSE_PUBLIC_KEY="your-public-key"
export LANGFUSE_SECRET_KEY="your-secret-key"

# Для LiteLLM (example4)
export OPENAI_API_KEY="your-openai-key"
export ANTHROPIC_API_KEY="your-anthropic-key"

# Полный список переменных см. в файле env.example
```

### Запуск примеров
```bash
python example1_langsmith_tracing.py
python example2_dspy_optimization.py
python example3_langfuse_monitoring.py
python example4_litellm_cost_control.py
```

## 📊 Что демонстрируют примеры

### Наблюдаемость
- **Трассировка полного жизненного цикла**: от входного запроса до финального ответа
- **Иерархическая структура**: родительские и дочерние операции
- **Метаданные и теги**: для фильтрации и группировки
- **Визуализация в UI**: диаграммы Ганта, временные линии

### Оптимизация
- **Автоматическая генерация промптов**: замена ручного промпт-инжиниринга
- **Метрико-ориентированный подход**: оптимизация под конкретные KPI
- **Портативность между моделями**: один код, разные провайдеры
- **A/B тестирование**: сравнение версий программ

### Контроль затрат
- **Многоуровневая архитектура**: кэш → маршрутизация → пакетирование
- **Семантическое кэширование**: умное переиспользование ответов
- **Динамическая маршрутизация**: выбор оптимальной модели по критериям
- **Бюджетное управление**: лимиты и оповещения

## 🛠 Архитектура решения

```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   Приложение    │    │   Наблюдаемость  │    │ Контроль затрат │
│                 │    │                  │    │                 │
│ ┌─────────────┐ │    │ ┌──────────────┐ │    │ ┌─────────────┐ │
│ │    DSPy     │◄┼────┤ │  LangSmith   │ │    │ │   LiteLLM   │ │
│ │ Оптимизация │ │    │ │ Трассировка  │ │    │ │Маршрутизация│ │
│ └─────────────┘ │    │ └──────────────┘ │    │ └─────────────┘ │
│                 │    │        или       │    │                 │
│ ┌─────────────┐ │    │ ┌──────────────┐ │    │ ┌─────────────┐ │
│ │   Агенты    │◄┼────┤ │  LangFuse    │ │    │ │Кэширование  │ │
│ │             │ │    │ │ Open Source  │ │    │ │             │ │
│ └─────────────┘ │    │ └──────────────┘ │    │ └─────────────┘ │
└─────────────────┘    └──────────────────┘    └─────────────────┘
```

## 💡 Ключевые принципы

### 1. Наблюдаемость как основа
- Каждый вызов LLM должен быть прослеживаемым
- Метаданные помогают в отладке и анализе
- Визуализация упрощает понимание поведения системы

### 2. Автоматизация вместо ручной работы
- DSPy заменяет ручной промпт-инжиниринг
- Оптимизаторы ищут лучшие решения автоматически
- Метрики направляют процесс улучшения

### 3. Экономическая эффективность
- Кэширование снижает количество запросов к API
- Маршрутизация выбирает оптимальные модели
- Пакетирование дает скидки от провайдеров

### 4. Production-ready подход
- Обработка ошибок и fallback стратегии
- Мониторинг и алертинг на критических метриках
- Масштабируемость и надежность системы

## 📈 Ожидаемые результаты

После внедрения этих техник команды обычно наблюдают:

- **🐛 Сокращение времени отладки в 8-10 раз**: с часов до минут
- **💰 Снижение затрат на API на 25-40%**: через оптимизацию запросов
- **📊 Повышение качества на 15-25%**: благодаря автоматической оптимизации
- **⚡ Ускорение разработки в 3-4 раза**: за счет автоматизации

## 🎯 Дальнейшие шаги

1. **Выберите инструмент наблюдаемости**: LangSmith (проприетарный) или LangFuse (open-source)
2. **Внедрите DSPy для критических компонентов**: начните с простых задач Q&A
3. **Настройте LiteLLM для контроля затрат**: маршрутизация и кэширование
4. **Создайте процесс непрерывного мониторинга**: дашборды и алерты

Помните: **инструменты работают лучше всего в комбинации**. Наблюдаемость показывает проблемы, DSPy их решает, а LiteLLM делает это экономично.

---

*Примеры созданы для образовательных целей и демонстрируют концепции, которые в production требуют дополнительной настройки и интеграции.*