#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä 3e: –ß–∞—Ç —Å OpenAI + LangFuse –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç:
- –†–µ–∞–ª—å–Ω—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é OpenAI API —Å LangFuse v3
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É LLM –≤—ã–∑–æ–≤–æ–≤
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ç–æ–∫–µ–Ω–æ–≤, —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∏—Å—Ç–æ—Ä–∏–∏
"""

import os
import time
from datetime import datetime
from typing import List, Dict, Any, Optional

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("‚úÖ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
except ImportError:
    print("‚ö†Ô∏è  python-dotenv –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
try:
    from langfuse import observe, get_client
    from langfuse.openai import openai  # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è LangFuse —Å OpenAI
    print("‚úÖ LangFuse SDK –¥–æ—Å—Ç—É–ø–µ–Ω")
    LANGFUSE_AVAILABLE = True
except ImportError:
    print("‚ùå LangFuse SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install langfuse")
    LANGFUSE_AVAILABLE = False
    exit(1)

try:
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ OpenAI –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ LangFuse –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é
    openai.OpenAI()
    print("‚úÖ OpenAI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞")
    OPENAI_AVAILABLE = True
except Exception as e:
    print(f"‚ùå OpenAI –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai")
    OPENAI_AVAILABLE = False


class IntelligentChatBot:
    """–£–º–Ω—ã–π —á–∞—Ç-–±–æ—Ç —Å –ø–æ–ª–Ω—ã–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º —á–µ—Ä–µ–∑ LangFuse"""
    
    def __init__(self, name: str = "ChatBot", model: str = "gpt-4o-mini"):
        self.name = name
        self.model = model
        self.conversation_history = []
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∏–µ–Ω—Ç—ã
        self.langfuse = get_client()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI —á–µ—Ä–µ–∑ LangFuse –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é
        self.openai_client = openai.OpenAI(
            api_key=os.getenv("OPENAI_API_KEY")
        )
        
        print(f"ü§ñ –ß–∞—Ç-–±–æ—Ç '{name}' –≥–æ—Ç–æ–≤ (–º–æ–¥–µ–ª—å: {model})")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self._check_configuration()
    
    def _check_configuration(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é API –∫–ª—é—á–µ–π"""
        
        print(f"\nüîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
        
        # OpenAI
        openai_key = os.getenv("OPENAI_API_KEY")
        print(f"  OpenAI API Key: {'‚úÖ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' if openai_key else '‚ùå –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}")
        
        # LangFuse  
        langfuse_host = os.getenv("LANGFUSE_HOST", "–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        langfuse_key = os.getenv("LANGFUSE_PUBLIC_KEY", "–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        print(f"  LangFuse Host: {langfuse_host}")
        print(f"  LangFuse Key: {'‚úÖ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' if langfuse_key != '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' else '‚ùå –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}")
        
        if not openai_key:
            print("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω!")
            print("   –î–æ–±–∞–≤—å—Ç–µ –≤ .env: OPENAI_API_KEY=–≤–∞—à-–∫–ª—é—á")
            return False
            
        return True
    
    @observe(name="chat_conversation")
    def start_conversation(self, user_id: str = "demo_user", session_id: Optional[str] = None) -> None:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é –±–µ—Å–µ–¥—É —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            session_id: ID —Å–µ—Å—Å–∏–∏ (–µ—Å–ª–∏ None, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
        """
        
        if session_id is None:
            session_id = f"session_{int(time.time())}"
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É –±–µ—Å–µ–¥—ã
        self.langfuse.update_current_trace(
            name="interactive_chat_session",
            user_id=user_id,
            session_id=session_id,
            tags=["interactive", "chat", "openai", self.model],
            metadata={
                "bot_name": self.name,
                "model": self.model,
                "started_at": datetime.now().isoformat()
            }
        )
        
        print(f"\nüí¨ –ù–∞—á–∏–Ω–∞–µ–º –±–µ—Å–µ–¥—É! (–°–µ—Å—Å–∏—è: {session_id})")
        print(f"   –ù–∞–ø–∏—à–∏—Ç–µ 'quit', 'exit' –∏–ª–∏ '—Å—Ç–æ–ø' –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è")
        print("=" * 60)
        
        total_messages = 0
        total_tokens = 0
        total_cost = 0.0
        
        try:
            while True:
                # –ü–æ–ª—É—á–∞–µ–º –≤–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                user_input = input(f"\nüë§ –í—ã: ").strip()
                
                if user_input.lower() in ['quit', 'exit', '—Å—Ç–æ–ø', '–≤—ã—Ö–æ–¥']:
                    print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                    break
                
                if not user_input:
                    print("‚ö†Ô∏è  –ü—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑")
                    continue
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
                response_data = self._process_message(user_input, user_id, session_id)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
                print(f"ü§ñ {self.name}: {response_data['response']}")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                total_messages += 1
                total_tokens += response_data.get('total_tokens', 0)
                total_cost += response_data.get('cost_estimate', 0.0)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                print(f"   üìä –¢–æ–∫–µ–Ω—ã: {response_data.get('total_tokens', 0)} | "
                      f"–°—Ç–æ–∏–º–æ—Å—Ç—å: ${response_data.get('cost_estimate', 0.0):.4f} | "
                      f"–í—Ä–µ–º—è: {response_data.get('response_time', 0.0):.2f}—Å")
        
        except KeyboardInterrupt:
            print("\n\nüëã –ë–µ—Å–µ–¥–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–µ—Å–µ–¥—ã
        self.langfuse.update_current_trace(
            output={
                "conversation_summary": {
                    "total_messages": total_messages,
                    "total_tokens": total_tokens,
                    "total_cost": total_cost,
                    "average_tokens_per_message": total_tokens / max(total_messages, 1),
                    "conversation_length": len(self.conversation_history)
                }
            },
            tags=["completed", f"messages-{total_messages}", f"tokens-{total_tokens}"]
        )
        
        print(f"\nüìä –ò—Ç–æ–≥–∏ –±–µ—Å–µ–¥—ã:")
        print(f"   –°–æ–æ–±—â–µ–Ω–∏–π: {total_messages}")
        print(f"   –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens}")
        print(f"   –û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${total_cost:.4f}")
        print(f"   –ò—Å—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {len(self.conversation_history)} —Å–æ–æ–±—â–µ–Ω–∏–π")
    
    @observe(name="process_user_message")
    def _process_message(self, user_input: str, user_id: str, session_id: str) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        
        start_time = time.time()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º span –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
        self.langfuse.update_current_span(
            input={
                "user_message": user_input,
                "user_id": user_id,
                "session_id": session_id,
                "conversation_length": len(self.conversation_history)
            },
            metadata={
                "message_length": len(user_input),
                "timestamp": datetime.now().isoformat()
            }
        )
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.conversation_history.append({
            "role": "user", 
            "content": user_input
        })
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç OpenAI
        llm_response = self._call_openai_api(self.conversation_history)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –±–æ—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
        assistant_message = llm_response["response"]
        self.conversation_history.append({
            "role": "assistant",
            "content": assistant_message
        })
        
        response_time = time.time() - start_time
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
        result = {
            "response": assistant_message,
            "response_time": response_time,
            "input_tokens": llm_response.get("input_tokens", 0),
            "output_tokens": llm_response.get("output_tokens", 0),
            "total_tokens": llm_response.get("total_tokens", 0),
            "cost_estimate": llm_response.get("cost_estimate", 0.0),
            "model_used": llm_response.get("model", self.model)
        }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º span —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
        self.langfuse.update_current_span(
            output=result,
            metadata={
                "response_length": len(assistant_message),
                "conversation_turn": len(self.conversation_history) // 2
            }
        )
        
        return result
    
    @observe(name="openai_api_call")
    def _call_openai_api(self, messages: List[Dict[str, str]]) -> Dict[str, Any]:
        """–í—ã–∑—ã–≤–∞–µ—Ç OpenAI API —Å –ø–æ–ª–Ω—ã–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º"""
        
        if not OPENAI_AVAILABLE:
            # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            return {
                "response": "–ò–∑–≤–∏–Ω–∏—Ç–µ, OpenAI API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –≠—Ç–æ –¥–µ–º–æ-–æ—Ç–≤–µ—Ç.",
                "input_tokens": 20,
                "output_tokens": 15,
                "total_tokens": 35,
                "cost_estimate": 0.0001,
                "model": "demo-model"
            }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º span –¥–ª—è LLM –≤—ã–∑–æ–≤–∞
        self.langfuse.update_current_span(
            input={
                "messages": messages,
                "model": self.model,
                "conversation_length": len(messages)
            },
            metadata={
                "api_provider": "openai",
                "model_family": "gpt"
            }
        )
        
        try:
            # –í—ã–∑–æ–≤ OpenAI API —á–µ—Ä–µ–∑ LangFuse –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é
            # –≠—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—Å—Ç generation –≤ LangFuse
            response = self.openai_client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=1000,
                # LangFuse –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ—Ö–≤–∞—Ç–∏—Ç —ç—Ç–æ—Ç –≤—ã–∑–æ–≤
                name="chat-response",  # –ò–º—è –¥–ª—è LangFuse generation
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞
            assistant_message = response.choices[0].message.content
            usage = response.usage
            
            # –ü—Ä–∏–º–µ—Ä–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏ (–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ü–µ–Ω—ã –º–æ–≥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è)
            cost_per_input_token = 0.00015 / 1000   # gpt-4o-mini input
            cost_per_output_token = 0.0006 / 1000   # gpt-4o-mini output
            
            cost_estimate = (
                usage.prompt_tokens * cost_per_input_token +
                usage.completion_tokens * cost_per_output_token
            )
            
            result = {
                "response": assistant_message,
                "input_tokens": usage.prompt_tokens,
                "output_tokens": usage.completion_tokens,
                "total_tokens": usage.total_tokens,
                "cost_estimate": cost_estimate,
                "model": self.model
            }
            
            # –û–±–Ω–æ–≤–ª—è–µ–º span —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
            self.langfuse.update_current_span(
                output=result,
                metadata={
                    "finish_reason": response.choices[0].finish_reason,
                    "response_id": response.id
                }
            )
            
            return result
            
        except Exception as e:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏ API
            error_result = {
                "response": f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}",
                "input_tokens": 0,
                "output_tokens": 0, 
                "total_tokens": 0,
                "cost_estimate": 0.0,
                "model": self.model,
                "error": str(e)
            }
            
            self.langfuse.update_current_span(
                output=error_result,
                metadata={"error": True}
            )
            
            return error_result
    
    @observe(name="get_conversation_summary")
    def get_conversation_summary(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ —Ç–µ–∫—É—â–µ–π –±–µ—Å–µ–¥–µ"""
        
        if not self.conversation_history:
            return {"message": "–ë–µ—Å–µ–¥–∞ –µ—â–µ –Ω–µ –Ω–∞—á–∞—Ç–∞"}
        
        user_messages = [msg for msg in self.conversation_history if msg["role"] == "user"]
        assistant_messages = [msg for msg in self.conversation_history if msg["role"] == "assistant"]
        
        summary = {
            "total_exchanges": len(user_messages),
            "total_messages": len(self.conversation_history),
            "average_user_message_length": sum(len(msg["content"]) for msg in user_messages) / len(user_messages),
            "average_assistant_message_length": sum(len(msg["content"]) for msg in assistant_messages) / len(assistant_messages),
            "conversation_start": datetime.now().isoformat() if self.conversation_history else None,
            "last_messages": self.conversation_history[-4:] if len(self.conversation_history) >= 4 else self.conversation_history
        }
        
        self.langfuse.update_current_span(
            input={"conversation_length": len(self.conversation_history)},
            output=summary
        )
        
        return summary


@observe(name="demo_automated_conversation")
def demo_automated_conversation():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –±–µ—Å–µ–¥—ã"""
    
    print("\nüéØ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –±–µ—Å–µ–¥—ã")
    print("=" * 60)
    
    bot = IntelligentChatBot("DemoBot", model="gpt-4o-mini")
    
    # –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –¥–µ–º–æ
    demo_messages = [
        "–ü—Ä–∏–≤–µ—Ç! –†–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ",
        "–ß—Ç–æ —Ç—ã –∑–Ω–∞–µ—à—å –æ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏?",
        "–ú–æ–∂–µ—à—å –æ–±—ä—è—Å–Ω–∏—Ç—å, —á—Ç–æ —Ç–∞–∫–æ–µ LLM?",
        "–°–ø–∞—Å–∏–±–æ –∑–∞ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—É—é –±–µ—Å–µ–¥—É!"
    ]
    
    langfuse = get_client()
    langfuse.update_current_trace(
        name="automated_demo_conversation",
        user_id="demo_user_auto",
        session_id="auto_demo_session",
        tags=["demo", "automated", "showcase"]
    )
    
    total_tokens = 0
    total_cost = 0.0
    
    for i, message in enumerate(demo_messages, 1):
        print(f"\nüë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {message}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        response_data = bot._process_message(
            user_input=message,
            user_id="demo_user_auto", 
            session_id="auto_demo_session"
        )
        
        print(f"ü§ñ {bot.name}: {response_data['response']}")
        print(f"   üìä –¢–æ–∫–µ–Ω—ã: {response_data['total_tokens']} | "
              f"–°—Ç–æ–∏–º–æ—Å—Ç—å: ${response_data['cost_estimate']:.4f} | "
              f"–í—Ä–µ–º—è: {response_data['response_time']:.2f}—Å")
        
        total_tokens += response_data['total_tokens']
        total_cost += response_data['cost_estimate']
        
        # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
        time.sleep(1)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–≤–æ–¥–∫—É
    summary = bot.get_conversation_summary()
    
    print(f"\nüìä –ò—Ç–æ–≥–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏:")
    print(f"   –û–±–º–µ–Ω–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏: {summary['total_exchanges']}")
    print(f"   –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {total_tokens}")
    print(f"   –û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${total_cost:.4f}")
    print(f"   –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {summary['average_assistant_message_length']:.0f} —Å–∏–º–≤–æ–ª–æ–≤")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("=== OpenAI Chat + LangFuse Monitoring ===")
    
    if not LANGFUSE_AVAILABLE:
        print("‚ùå LangFuse SDK –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return
    
    langfuse = get_client()
    
    print(f"\nüîß –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
    openai_key = os.getenv("OPENAI_API_KEY")
    langfuse_key = os.getenv("LANGFUSE_PUBLIC_KEY")
    
    if not openai_key:
        print("‚ö†Ô∏è  OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
        print("   –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å –∑–∞–≥–ª—É—à–∫–∞–º–∏")
    
    if not langfuse_key:
        print("‚ö†Ô∏è  LangFuse –∫–ª—é—á–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
        print("   –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã –ª–æ–∫–∞–ª—å–Ω–æ")
    
    try:
        # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞
        print(f"\nüéØ –í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:")
        print("   1. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Ç")
        print("   2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è")
        print("   3. –û–±–∞ —Ä–µ–∂–∏–º–∞")
        
        choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä (1-3) –∏–ª–∏ Enter –¥–ª—è –¥–µ–º–æ: ").strip()
        
        if choice in ['1', '']:
            # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —á–∞—Ç
            bot = IntelligentChatBot("ChatGPT-Assistant", model="gpt-4o-mini")
            bot.start_conversation(user_id="interactive_user")
            
        elif choice == '2':
            # –¢–æ–ª—å–∫–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è
            demo_automated_conversation()
            
        elif choice == '3':
            # –û–±–∞ —Ä–µ–∂–∏–º–∞
            demo_automated_conversation()
            
            print(f"\n" + "="*60)
            input("–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –∫ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–º—É —á–∞—Ç—É...")
            
            bot = IntelligentChatBot("ChatGPT-Assistant", model="gpt-4o-mini")
            bot.start_conversation(user_id="interactive_user")
        
        else:
            print("‚ö†Ô∏è  –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä, –∑–∞–ø—É—Å–∫–∞—é –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é")
            demo_automated_conversation()
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –≤ LangFuse
        langfuse.flush()
        print(f"\nüì§ –í—Å–µ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –≤ LangFuse")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        langfuse_host = os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com")
        print(f"\nüåê –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ LangFuse:")
        print(f"   {langfuse_host}")
        print(f"\n‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        
    except KeyboardInterrupt:
        print(f"\nüëã –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
