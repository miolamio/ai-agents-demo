#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä 3d: –§–∏–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å LangFuse v3

–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç:
- –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ LangFuse v3 SDK
- –î–µ–∫–æ—Ä–∞—Ç–æ—Ä @observe –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏
- –†–µ–∞–ª—å–Ω—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å –Ω–∞—Å—Ç–æ—è—â–∏–º LangFuse —Å–µ—Ä–≤–µ—Ä–æ–º
- –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –∏ spans
"""

import os
import time
from datetime import datetime
from typing import List, Dict, Any

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("‚úÖ –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
except ImportError:
    print("‚ö†Ô∏è  python-dotenv –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

# –ü—Ä–æ–≤–µ—Ä–∏–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LangFuse SDK
try:
    from langfuse import observe, get_client
    print("‚úÖ LangFuse v3 SDK –¥–æ—Å—Ç—É–ø–µ–Ω")
    LANGFUSE_AVAILABLE = True
except ImportError:
    print("‚ùå LangFuse SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install langfuse")
    LANGFUSE_AVAILABLE = False
    exit(1)


class SmartAgent:
    """–£–º–Ω—ã–π –∞–≥–µ–Ω—Ç —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π LangFuse v3"""
    
    def __init__(self, name: str = "SmartAgent"):
        self.name = name
        
        # –ü–æ–ª—É—á–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç LangFuse
        self.langfuse = get_client()
        
        print(f"ü§ñ –ê–≥–µ–Ω—Ç '{name}' –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        print(f"üîó LangFuse –∫–ª–∏–µ–Ω—Ç –≥–æ—Ç–æ–≤")
    
    @observe(name="process_user_request")
    def process_user_request(self, user_query: str, user_id: str, session_id: str) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –ø–æ–ª–Ω–æ–π —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–æ–π
        
        Args:
            user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è  
            session_id: ID —Å–µ—Å—Å–∏–∏
            
        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
        self.langfuse.update_current_trace(
            user_id=user_id,
            session_id=session_id,
            tags=["user-request", "production"],
            metadata={
                "agent_name": self.name,
                "query_length": len(user_query),
                "timestamp": datetime.now().isoformat()
            }
        )
        
        print(f"üìù –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∑–∞–ø—Ä–æ—Å: '{user_query[:50]}...'")
        
        # –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        analysis = self._analyze_query(user_query)
        
        # –®–∞–≥ 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        response = self._generate_response(analysis)
        
        # –®–∞–≥ 3: –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
        final_result = self._postprocess_result(response)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É —Å —Ñ–∏–Ω–∞–ª—å–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
        self.langfuse.update_current_trace(
            output={
                "response": final_result["response"],
                "confidence": final_result["confidence"],
                "processing_time": final_result["processing_time"]
            },
            tags=["completed", f"confidence-{final_result['confidence']}"]
        )
        
        return final_result
    
    @observe(name="analyze_query")
    def _analyze_query(self, query: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å"""
        
        print(f"  üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∑–∞–ø—Ä–æ—Å...")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π span
        self.langfuse.update_current_span(
            input={"query": query, "length": len(query)},
            metadata={"step": "analysis", "model": "analysis-v1"}
        )
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑
        time.sleep(0.1)
        
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –Ω–∞–º–µ—Ä–µ–Ω–∏–π
        intent = "question" if "?" in query else "statement"
        confidence = 0.9 if "?" in query else 0.7
        entities = query.split()[:3]  # –ü–µ—Ä–≤—ã–µ 3 —Å–ª–æ–≤–∞ –∫–∞–∫ —Å—É—â–Ω–æ—Å—Ç–∏
        
        result = {
            "intent": intent,
            "confidence": confidence,
            "entities": entities,
            "language": "ru" if any(ord(c) > 127 for c in query) else "en",
            "complexity": "simple" if len(query.split()) < 5 else "complex"
        }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º span —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
        self.langfuse.update_current_span(
            output=result,
            metadata={"entities_count": len(entities)}
        )
        
        print(f"    ‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {intent} ({confidence})")
        return result
    
    @observe(name="generate_response")
    def _generate_response(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
        
        print(f"  üéØ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º span
        self.langfuse.update_current_span(
            input=analysis,
            metadata={"step": "generation", "model": "response-generator-v2"}
        )
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–∞
        time.sleep(0.2)
        
        intent = analysis["intent"]
        entities = analysis["entities"]
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        if intent == "question":
            response = f"–û—Ç–≤–µ—á–∞—é –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å –æ {', '.join(entities[:2])}"
        else:
            response = f"–ü–æ–Ω—è–ª –≤–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ {', '.join(entities[:2])}"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        if analysis["complexity"] == "complex":
            response += ". –≠—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –∏ —Å–ª–æ–∂–Ω—ã–π –≤–æ–ø—Ä–æ—Å, —Ç—Ä–µ–±—É—é—â–∏–π –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è."
        
        result = {
            "response": response,
            "model_used": "response-generator-v2",
            "temperature": 0.7,
            "tokens_used": len(response.split()) + len(' '.join(entities)),
            "generation_time": 0.2
        }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º span
        self.langfuse.update_current_span(
            output=result,
            metadata={
                "response_length": len(response),
                "tokens": result["tokens_used"]
            }
        )
        
        print(f"    ‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω ({result['tokens_used']} —Ç–æ–∫–µ–Ω–æ–≤)")
        return result
    
    @observe(name="postprocess_result")
    def _postprocess_result(self, generation: Dict[str, Any]) -> Dict[str, Any]:
        """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        
        print(f"  üîß –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞...")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º span
        self.langfuse.update_current_span(
            input=generation,
            metadata={"step": "postprocessing"}
        )
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫—É
        time.sleep(0.05)
        
        # –†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –∏ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        confidence_score = 0.95 if generation["tokens_used"] > 10 else 0.8
        processing_time = generation.get("generation_time", 0) + 0.05
        
        result = {
            "response": generation["response"].strip(),
            "confidence": confidence_score,
            "processing_time": processing_time,
            "tokens_used": generation["tokens_used"],
            "safety_check": "passed",
            "content_filter": "clean",
            "final_review": "approved"
        }
        
        # –û–±–Ω–æ–≤–ª—è–µ–º span
        self.langfuse.update_current_span(
            output=result,
            metadata={"confidence_score": confidence_score}
        )
        
        print(f"    ‚úÖ –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence_score})")
        return result


@observe(name="conversation_simulation")
def simulate_conversation(agent: SmartAgent, messages: List[str], user_id: str, session_id: str) -> List[Dict[str, Any]]:
    """–°–∏–º—É–ª–∏—Ä—É–µ—Ç –¥–∏–∞–ª–æ–≥ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º"""
    
    langfuse = get_client()
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫—É –¥–∏–∞–ª–æ–≥–∞
    langfuse.update_current_trace(
        name="multi-turn-conversation",
        user_id=user_id,
        session_id=session_id,
        tags=["conversation", "simulation", "multi-turn"],
        metadata={
            "total_messages": len(messages),
            "conversation_type": "simulation"
        }
    )
    
    results = []
    total_tokens = 0
    total_time = 0
    
    for i, message in enumerate(messages, 1):
        print(f"\nüí¨ –°–æ–æ–±—â–µ–Ω–∏–µ {i}/{len(messages)}: {message}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        result = agent.process_user_request(
            user_query=message,
            user_id=user_id,
            session_id=session_id
        )
        
        results.append(result)
        total_tokens += result["tokens_used"]
        total_time += result["processing_time"]
        
        print(f"ü§ñ –û—Ç–≤–µ—Ç: {result['response']}")
        print(f"üìä –¢–æ–∫–µ–Ω—ã: {result['tokens_used']}, –í—Ä–µ–º—è: {result['processing_time']:.2f}—Å")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–∏–∞–ª–æ–≥–∞
    langfuse.update_current_trace(
        output={
            "messages_processed": len(messages),
            "total_tokens": total_tokens,
            "total_time": total_time,
            "average_confidence": sum(r["confidence"] for r in results) / len(results),
            "conversation_summary": f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π"
        },
        tags=["completed", f"messages-{len(messages)}", f"tokens-{total_tokens}"]
    )
    
    return results


def demo_basic_functionality():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
    
    print("\nüéØ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 1: –ë–∞–∑–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å")
    print("=" * 60)
    
    agent = SmartAgent("DemoAgent")
    
    # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å
    result = agent.process_user_request(
        user_query="–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?",
        user_id="demo_user_1",
        session_id="demo_session_1"
    )
    
    print(f"\nüìã –†–µ–∑—É–ª—å—Ç–∞—Ç:")
    print(f"  –û—Ç–≤–µ—Ç: {result['response']}")
    print(f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']}")
    print(f"  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result['processing_time']:.2f}—Å")
    print(f"  –¢–æ–∫–µ–Ω—ã: {result['tokens_used']}")


def demo_conversation():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –¥–∏–∞–ª–æ–≥–∞"""
    
    print("\nüéØ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è 2: –ú–Ω–æ–≥–æ–æ–±–æ—Ä–æ—Ç–Ω—ã–π –¥–∏–∞–ª–æ–≥")
    print("=" * 60)
    
    agent = SmartAgent("ConversationAgent")
    
    # –î–∏–∞–ª–æ–≥
    messages = [
        "–ü—Ä–∏–≤–µ—Ç! –†–∞—Å—Å–∫–∞–∂–∏ –æ LangFuse",
        "–ö–∞–∫ –æ–Ω –ø–æ–º–æ–≥–∞–µ—Ç –≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ LLM?", 
        "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ!"
    ]
    
    results = simulate_conversation(
        agent=agent,
        messages=messages,
        user_id="demo_user_2", 
        session_id="demo_session_2"
    )
    
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∏–∞–ª–æ–≥–∞:")
    print(f"  –°–æ–æ–±—â–µ–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(results)}")
    print(f"  –û–±—â–µ–µ –≤—Ä–µ–º—è: {sum(r['processing_time'] for r in results):.2f}—Å")
    print(f"  –û–±—â–∏–µ —Ç–æ–∫–µ–Ω—ã: {sum(r['tokens_used'] for r in results)}")
    print(f"  –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {sum(r['confidence'] for r in results) / len(results):.2f}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    
    print("=== LangFuse v3 SDK - –§–∏–Ω–∞–ª—å–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è ===")
    
    if not LANGFUSE_AVAILABLE:
        print("‚ùå LangFuse SDK –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    langfuse = get_client()
    
    print(f"\nüîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
    host = os.getenv("LANGFUSE_HOST", "–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    public_key = os.getenv("LANGFUSE_PUBLIC_KEY", "–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    print(f"  Host: {host}")
    print(f"  Public Key: {'‚úÖ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' if public_key != '–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω' else '‚ùå –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω'}")
    
    if public_key == "–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω":
        print("\n‚ö†Ô∏è  API –∫–ª—é—á–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã, –Ω–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—Å—è")
        print("   (—Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã, –Ω–æ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã)")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    try:
        demo_basic_functionality()
        demo_conversation()
        
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
        langfuse.flush()
        print(f"\nüì§ –í—Å–µ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –≤ LangFuse")
        
        print(f"\nüåê –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ:")
        if host != "–Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω":
            print(f"   {host}")
        else:
            print(f"   https://cloud.langfuse.com (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–±–ª–∞—á–Ω–∞—è –≤–µ—Ä—Å–∏—è)")
        
        print(f"\n‚úÖ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
